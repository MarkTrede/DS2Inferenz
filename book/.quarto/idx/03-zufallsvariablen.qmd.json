<<<<<<< Updated upstream
{"title":"Zufallsvariablen","markdown":{"headingText":"Zufallsvariablen","headingAttr":{"id":"sec-zufallsvariablen","classes":[],"keyvalue":[]},"containsRefs":false,"markdown":"\nDie wichtigsten formalen Grundlagen der Wahrscheinlichkeitstheorie sind nun gelegt. Darauf aufbauend definieren wir Zufallsvariablen. Zufallsvariablen sind - intuitiv gesprochen - Zahlen, deren Wert man noch nicht kennt, deren Wert sich aber (irgendwann) realisiert. Die formale Definition von Zufallsvariablen bezieht sich auf die Ergebnismenge.\n\n::: callout-note\n## Definition: Zufallsvariable\n\nEine Abbildung \n$$\nX: \\Omega\\rightarrow \\mathbb{R}\n$$ \nheißt **Zufallsvariable** (engl. random variable).\n:::\n\nEine Zufallsvariable kann man sich zwar als eine Zahl vorstellen, deren Wert man noch nicht kennt. Formal gesehen handelt es sich jedoch um eine Funktion, die jedem Element der Ergebnismenge genau eine reelle Zahl zuordnet.\n\n::: { .callout-tip collapse=\"true\"}\n## Beispiel: Summe der Augenzahl\n\nAls Beispiel betrachten wir ein Zufallsexperiment, bei dem zwei Würfel geworfen\nwerden. Jeder der beiden Würfel zeigt dann 1, 2, 3, 4, 5 oder 6.\nDer Ergebnisraum hat folglich 36 Elemente, nämlich\n$$\n\\Omega=\\{11,12,13,14,15,16,21,22,23,\\ldots,65,66\\}.\n$$\nNun definieren wir die Zufallsvariable $X$: \"Summe der Augenzahlen\".\nOffensichtlich kann es passieren, dass beide\nWürfel 1 zeigen, dann ist $X=2$. Wenn einer der Würfel eine 1 anzeigt,\nder andere eine 2, dann ist $X=3$ usw. Die Abbildung bzw. Funktion aus dem \nErgebnisraum in die Menge der reellen Zahlen sieht also so aus:\n$$\n\\begin{array}{lll}\n\\Omega & X & \\mathbb{R}\\\\\\hline\n11 & \\longrightarrow & 2\\\\\n12 & \\longrightarrow & 3\\\\\n13 & \\longrightarrow & 4\\\\\n14 & \\longrightarrow & 5\\\\\n15 & \\longrightarrow & 6\\\\\n16 & \\longrightarrow & 7\\\\\n21 & \\longrightarrow & 3\\\\\n22 & \\longrightarrow & 4\\\\\n23 & \\longrightarrow & 5\\\\\n\\vdots&&\\vdots\\\\\n65 & \\longrightarrow & 11\\\\\n66 & \\longrightarrow & 12\n\\end{array}\n$$\n:::\n\nWenn die Zufallsvariable sich realisiert, bezeichnet man die **Realisation** gewöhnlich mit einem Kleinbuchstaben. Beispielsweise ist $x$ die Realisation der Zufallsvariable $X$. Allerdings werden Kleinbuchstaben auch in ihrer sonstigen Funktion als Variablennamen verwendet, man muss also auf den Kontext achten. Gedanklich ist es oft hilfreich, sich $X$ (also die Zufallsvariable) als die Situation ex ante und $x$ (also die Realisierung) als die Situation ex post vorzustellen.\n\nBeachten Sie den großen Unterschied zwischen einer Zufallsvariable und ihrer Realisation. Die Zufallsvariable ist eine Funktion, die Realisation ist eine reelle Zahl. Wahrscheinlichkeitsaussagen lassen sich nur über Zufallsvariablen treffen, nicht über ihre Realisation.\n\n::: { .callout-tip collapse=\"true\"}\n## Beispiel: Summe der Augenzahlen\n\nWir betrachten weiterhin das Zufallsexperiment mit zwei Würfeln. \nWie hoch ist die Wahrscheinlichkeit, dass die Zufallsvariable $X$: \"Summe\nder beiden Augenzahlen\" den Wert 4 annimmt? Um diese eigentlich sehr einfache\nFrage in dem formalen Rahmen sauber zu beantworten, müssen wir zunächst \nermitteln, welche Ergebnisse aus $\\Omega$ dazu führen, dass $X=4$ ist (das\nsogenannte Urbild von $X=4$).\n\nEs gibt drei Ergebnisse, die auf $X=4$ führen, nämlich $13,22$ und $31$. \nNun fragen wir uns, wie wahrscheinlich das Ereignis $\\{13,22,31\\}$ ist? Die\nAntwort ist einfach, weil es sich um ein Laplace-Experiment handelt,\n$$\nP(X=4)=P(\\{13,22,31\\})=\\frac{|(\\{13,22,31\\}|}{|\\Omega|}=\\frac{3}{36}=\\frac{1}{12}.\n$$\n:::\n\nUm mit Zufallsvorgängen in der Ökonomik zu arbeiten, sind Zufallsvariablen eine \ngroße Hilfe. Praktisch alle Vorgänge, bei denen der Zufall oder Unwissenheit \neine Rolle spielen, lassen sich gut mit Hilfe von Zufallsvariablen beschreiben. \nIn fast allen Fällen wird die Funktion\n$X:\\Omega\\to\\mathbb{R}$ nicht explizit angegeben, sondern implizit als\nvorhanden vorausgesetzt. Auch die Ergebnismenge wird im allgemeinen nicht \nausdrücklich aufgeschrieben. Trotzdem ist es wichtig zu erkennen, dass \nZufallsvariablen auf dem mengentheoretischen Fundament aufbauen, dass\nwir in den vorangegangenen Kapiteln gelegt haben und deshalb eine\nsaubere mathematische Grundlage haben.\n\n::: { .callout-tip collapse=\"true\"}\n## Beispiele: Ökonomische Zufallsvariablen\n\nMögliche Zufallsvariablen in der Ökonomik:\n\n- Die Zufallsvariable $X$ steht für die Rendite einer Aktiengesellschaft im kommenden Jahr. Wenn das Jahr vergangen ist, hat sich die Rendite $x$ realisiert. Von den ex ante vielen möglichen Renditen hat sich nur eine tatsächlich eingestellt.\n\n- $X$ bezeichnet den Erwerbsstatus einer zufällig aus einer Population ausgewählten Person. Der Erwerbsstatus wird durch eine Zahl kodiert: 0=nicht erwerbstätig, 1=Teilzeit, 2=Vollzeit. Sobald eine Person tatsächlich ausgewählt und befragt wurde, hat sich die Zufallsvariable realisiert und es ist dann entweder $x=0$ oder $x=1$ oder $x=2$.\n\n- $X$ ist das Nettomonatseinkommen eines zufällig ausgewählten Haushalts einer Population. Nachdem ein Haushalt zufällig ausgewählt und befragt wurde, hat sich die Zufallsvariable realisiert und ist zum Beispiel $x=4321$.\n\n- $X$ ist die Dauer, die ein technisches Gerät ohne Fehler funktioniert. \nBeim ersten Start des Geräts weiß man noch nicht, wie lange es fehlerfrei laufen wird. Sobald ein Fehler auftritt, hat sich die Zufallsvariable realisiert. Die Realisation ist dann beispielsweise $x=12345$ Stunden.\n:::\n\n## Verteilungsfunktion\n\nWir wissen zwar nicht, welchen Wert eine Zufallsvariable annehmen wird, aber oft wissen wir, dass bestimmte Werte mit einer höheren Wahrscheinlichkeit vorkommen als andere Werte. So wissen wir zum Beispiel, dass beim Werfen mit zwei Würfeln die Augensumme 2 weniger wahrscheinlich ist als die Augensumme 7, denn für die Augensumme 2 müssen beide Würfel eine 1 zeigen, für die Augensumme 7 gibt es dagegen viel mehr Möglichkeiten (nämlich 16, 25, 34, 43, 52 und 61). Um die Verteilung einer Zufallsvariable zu beschreiben, gibt es mehrere Möglichkeiten. Eine besonders wichtige ist die Verteilungsfunktion.\n\n::: callout-note\n## Definition: Verteilungsfunktion\n\nDie **Verteilungsfunktion** (engl. cumulative distribution function, cdf) einer Zufallsvariable $X$ gibt für $x\\in\\mathbb{R}$ die Wahrscheinlichkeit an, dass $X\\le x$ ist,\n$$\nF_X(x)=P(\\{\\omega: X(\\omega)\\le x\\})\n$$\noder in Kursschreibweise\n$$\nF_X(x)=P(X\\le x).\n$$\nWenn die Zufallsvariable sich aus dem Kontext erschließt, schreibt man auch\nanstelle von $F_X(x)$ einfach $F(x)$.\n:::\n\nIn der Definition wird die Verteilungsfunktion einer Zufallsvariable zurückgeführt auf \nWahrscheinlichkeiten von Ereignissen. Dabei werden ganz spezielle Ereignisse\nbetrachtet, nämlich $\\{\\omega:X(\\omega)\\le x\\}$. Es gibt also für jedes \nbeliebige $x\\in\\mathbb{R}$ ein solches Ereignis. Für ein gegebenes $x$ enthält\ndas Ereignis alle Ergebnisse, die dazu führen, dass die Zufallsvariable \nden Wert $x$ nicht überschreitet. Die kompliziertere Notation,\nin der das Ereignis ausdrücklich hingeschrieben wird, benutzt man in der\nPraxis sehr viel seltener als die Kurzschreibweise. Man sollte sie trotzdem \nkennen und vor allem verstehen, \ndamit die enge Verbindung zwischen Zufallsvariablen und \nEreignissen klar ist.  Die Verteilungsfunktion einer Zufallsvariable ist sehr nützlich, \nweil durch sie die Verteilung der Zufallsvariable eindeutig charakterisiert wird. \nKennt man die Verteiliungsfunktion, dann weiß man alles über die Vertelung, was \nwichtig ist.\n\nDie Verteilungsfunktion ist - wie der Name schon sagt - eine Funktion. Ihr\nDefinitionsbereich ist die Menge der reellen Zahlen $\\mathbb{R}$. Man darf also\njede beliebige Zahl in die Funktion einsetzen. Der Wertebereich der Verteilungsfunktion\nist das Intervall $[0,1]$, da es sich um eine Wahrscheinlichkeit handelt.\nVerteilungsfunktionen sind (wegen ihrer Konstruktion) immer monoton wachsend. Sie\nverlaufen niemals fallend, es kann jedoch sein, dass sie in einigen Bereichen \nflach verlaufen und nicht steigen. Verteilungsfunktionen können stetig sein,\nsie können aber auch Sprünge aufweisen.\n\nWenn man die Verteilungsfunktion $F_X(x)$ für immer kleinere Werte von $x$ auswertet,\ndann erreicht man (zumindest als Grenzwert) die 0, d.h.\n$$\n\\lim_{x\\to -\\infty} F_X(x)=0.\n$$\nFür immer größere Werte von $x$ erreicht man (zumindest als Grenzwert) die 1, d.h.\n$$\n\\lim_{x\\to\\infty} F_X(x)=1.\n$$\nFür praktisch alle Anwendungen reicht es aus, sich auf zwei Klassen\nvon Verteilungsfunktionen einzuschränken:\n\n- Die eine Klasse sind Treppenfunktionen\n(Stufenfunktionen), d.h. die Verteilungsfunktion hat Sprünge und verläuft \nzwischen den Sprüngen waagerecht. Zufallsvariablen, die eine solche\nVerteilungsfunktion haben, nennt man diskrete Zufallsvariablen. \n\n- Die andere Klasse sind stetige Verteilungsfunktionen (d.h. ohne Sprünge).\nZufallsvariablen mit einer stetigen Verteilungsfunktion nennt man\nstetige Zufallsvariablen.\n\nIm folgenden wird genauer definiert, wann Zufallsvariablen diskret oder\nstetig sind und was für Eigenschaften diskrete und stetige\nZufallsvariablen haben.\n\n## Diskrete Zufallsvariablen {#sec-diskrete_zv}\n\n::: callout-note\n## Definition: Diskrete Zufallsvariable\n\nEine Zufallsvariable heißt **diskret** (engl. discrete), wenn es \n\n- endliche viele Punkte $x_1, x_2,\\ldots, x_J$ oder\n- abzählbar unendlich viele Punkte $x_1, x_2,\\ldots$\n\ngibt mit der Eigenschaft \n$$\np_j=P(X=x_j)>0\n$$\nfür alle $j$ und\n$$\n\\sum_j p_j=1.\n$$\n:::\n\nOhne tiefer in die Mengenlehre einzusteigen, sei hier nur erwähnt, dass eine\nMenge abzählbar unendlich ist, wenn man ihre Elemente mit den natürlichen \nZahlen durchnummerieren kann. Abzählbar unendlich sind zum Beispiel die Menge\nder natürlichen Zahlen $\\mathbb{N}$, die Menge der ganzen Zahlen  $\\mathbb{Z}$ \nund die Menge aller Brüche $\\mathbb{B}$, nicht jedoch die Menge der\nreellen Zahlen  $\\mathbb{R}$ oder ein Intervall reeller Zahlen. Letztere\nnennt man überabzählbar unendlich.\n\nDie Menge aller Werte, die eine diskret verteilte Zufallsvariable annehmen kann, \nnennt man den Träger (engl. support) der Verteilung. Für endliche viele\nAusprägungen ist der Träger\n$$\nT_X=\\{x_1,\\ldots,x_J\\},\n$$\nund für (abzählbar) unendlich viele Ausprägungen ist er\n$$\nT_X=\\{x_1,x_2,x_3,\\ldots\\}.\n$$\nDie Funktion \n$$\nf_X(x)=\\left\\{\\begin{array}{ll}\np_j & \\text{ wenn }x=x_j\\\\\n0 &\\text{ sonst}\n\\end{array}\\right.\n$$\nheißt **Wahrscheinlichkeitsfunktion**. Gelegentlich finden Sie auch\ndie Bezeichnung Dichte für die Wahrscheinlichkeitsfunktion einer\ndiskreten Zufallsvariable. Den Subindex lässt man weg und schreibt\n$f(x)$, wenn aus dem Kontext hervorgeht, zu welcher Zufallsvariable\ndie Wahrscheinlichkeitsfunktion gehört.\n\nDie Verteilungsfunktion einer diskreten Zufallsvariable ist eine\nTreppenfunktion. Der Träger der Zufallsvariable gibt an, an welchen\nStellen die Treppenstufen liegen. Die erste Stufe ist an der Stelle $x_1$,\ndie zweite an der Stelle $x_2$ etc. Die Stufenhöhen sind $p_1, p_2,\\ldots,$.\n\nDie folgenden Abbildung zeigt die Verteilungsfunktion einer Zufallsvariablen $X$.\nHier und bei den folgenden Abbildungen im Rest dieses eLehrbuchs können Sie den R-Code, mit dem die Grafiken erzeugt werden, aufklappen. Er wird jedoch nicht näher erklärt und ist zum Verständnis des Inhalts auch nicht notwendig.\n```{r}\n#| code-fold: true\n#| code-summary: \"R-Code zeigen\"\nx <- c(0, 3, 4, 9)\ny <- c(0, 0.3, 0.4, 0.6, 1)\nplot(stepfun(x, y),\n     verticals=FALSE, \n     pch=19,\n     xlab=\"x\",\n     ylab=\"F(x)\",\n     main=\"Verteilungsfunktion\")\n```\nAn dieser Verteilungsfunktion lässt sich ablesen, dass\n\n- $X$ diskret verteilt ist, denn die Verteilungsfunktion ist eine Treppenfunktion,\n- $X$ den Wert $x_1=0$ mit einer Wahrscheinlichkeit von 0.3 annimmt, denn an der Stelle 0 springt die Verteilungsfunktion um 0.3 nach oben,\n- $X$ den Wert $x_2=3$ mit einer Wahrscheinlichkeit von 0.1 annimmt, denn an der Stelle 3 springt die Verteilungsfunktion um 0.1 nach oben,\n- den Wert $x_3=4$ mit einer Wahrscheinlichkeit von 0.2 annimmt \n- und den Wert $x_4=9$ mit einer Wahrscheinlichkeit von 0.4 annimmt.\n\nDie schwarzen Punkte zeigen, dass der Funktionswert an einer Sprungstelle immer\nder obere Wert ist. Man nennt die Treppenfunktion rechts-stetig, denn\nwenn man von der Sprungstelle ein winziges Stück nach rechts wandert, ändert\nsich der Funktionswert nicht. Wandert man ein winziges Stück nach links,\nspringt man auf die tiefere Stufe zurück.\n\n::: { .callout-tip collapse=\"true\"}\n## Beispiel: Anzahl der Sechsen bei zwei Würfeln\n\nZwei Würfel werden geworfen. Die Zufallsvariable $X$ sei die Anzahl\nder Sechsen. Sie kann also nur die Wert 0, 1 oder 2 annehmen\n(Träger). Die Wahrscheinlichkeitsfunktion ist\n$$\nf(x)=\\left\\{\n\\begin{array}{ll}\n25/36 & \\text{ für }x=0\\\\\n10/36 & \\text{ für }x=1\\\\\n1/36 & \\text{ für }x=2\\\\\n0 & \\text{ sonst.}\n\\end{array}\n\\right.\n$$\nDie zugehörige Verteilungsfunktion lautet\n$$\nF(x)=\\left\\{\n\\begin{array}{ll}\n0 & \\text{ für }x<0\\\\\n25/36 & \\text{ für }0\\le x<1\\\\\n35/36 & \\text{ für }1\\le x<2\\\\\n1 & \\text{ für }x\\ge 2.\n\\end{array}\n\\right.\n$$\nbzw. als Grafik\n```{r}\n#| code-fold: true\n#| code-summary: \"R-Code zeigen\"\nx <- c(0, 1, 2)\ny <- c(0, 25/36, 35/36, 1)\nplot(stepfun(x,y),\n     verticals=FALSE, \n     pch=19,\n     xlab=\"x\",\n     ylab=\"F(x)\",\n     main=\"Verteilungsfunktion\")\n```\n:::\n\n## Stetige Zufallsvariablen\n\n::: callout-note\n## Definition: Stetige Zufallsvariable\n\nEine Zufallsvariable $X$ heißt **stetig** (engl. continuous), wenn es eine\nFunktion $f_X(x)$ gibt, so dass\n$$\nF_X(x)=\\int_{-\\infty}^x f_X(t)dt\n$$\nfür alle $x\\in\\mathbb{R}$. Die Funktion $f_X(x)$ heißt **Dichtefunktion**\noder **Dichte** (engl. density function, density, \nprobability density function, pdf). \n:::\n\nWenn aus dem Kontext hervorgeht, zu welcher Zufallsvariable eine Dichte \ngehört, lässt man den Subindex gewöhnlich weg und schreibt einfach $f(x)$.\nDie Dichte hat folgende Eigenschaften:\n\n- Die Dichte kann nicht negativ sein, da sonst die Verteilungsfunktion\nnicht mehr monoton wachsend wäre. Es gilt also $f(x)\\le 0$ für alle $x\\in\\mathbb{R}$.\n\n- Die Fläche unter der Dichte muss 1 ergeben, da jede Verteiliungsfunktion $F(x)$\nfür $x\\to\\infty$ gegen 1 konvergiert. Es gilt also\n$$\n\\int_{-\\infty}^\\infty f(x)dx=1.\n$$\n\n- Die Dichte gibt an, wie steil die Verteilungsfunktion verläuft. Für\nalle Stellen, an denen die Verteilungsfunktion differenzierbar ist, gilt daher\n$$\nf(x)=F'(x).\n$$\nEs ist jedoch nicht unbedingt nötig, dass die Verteilungsfunktion überall\ndifferenzierbar ist, sie darf nicht differenzierbare Knicke enthalten.\nWenn es nicht differenzierbare Stellen in der Verteilungsfunktion gibt,\ndann weist die Dichte an diesen Stellen einen Sprung auf. \n\n- Der Wert der Dichte an einer Stelle $x$ ist *keine* Wahrscheinlichkeit.\nHingegen ist die Fläche unter der Dichte eine Wahrscheinlichkeit. So gilt\nbeispielsweise\n$$\nP(a<X\\le b)=\\int_a^b f(x)dx.\n$$\n\n- Die Wahrscheinlichkeit, dass eine stetige Zufallsvariable exakt den Wert\n$x$ annimmt, ist also (für jedes $x\\in\\mathbb{R}$)\n$$\nP(X=x)=0.\n$$\nDas impliziert, dass es (im Gegensatz zu diskreten Zufallsvariablen) \nbei stetigen Zufallsvariablen keine Rolle spielt, ob in einer Ungleichung\ndie Gleichheit enthalten ist oder nicht, d.h.\n$$\nP(X\\le x)=P(X<x),\\qquad P(X\\ge x)=P(X>x)\n$$\n\n- Die Menge $T_X=\\{x: f_X(x)>0\\}$ ist der Träger (engl. support)\nder Zufallsvariable $X$. Der Träger enthält alle Werte, die die\nZufallsvariable im Prinzip annehmen könnte.\n\nObwohl die Dichte selbst keine Wahrscheinlichkeit ist, hilft sie beim\nintuitiven Verständnis einer Verteilung trotzdem sehr. Man erkennt an \neinem Dichte-Plot sofort, in in welchen Bereichen die Zufallsvariable\nmit großer Wahrscheinlichkeit liegen wird und wo es eher unwahrscheinlich\nist.\n\n::: { .callout-tip collapse=\"true\"}\n## Beispiel: Dichte- und Verteilungsfunktion\n\nDie Dichte der Zufallsvariable $X$ sei \n$$\nf(x)=\\left\\{\n\\begin{array}{ll}\n0 & \\text{ wenn }x < -0.56\\\\\n-x^4+x^2+0.5 & \\text{ wenn }-0.56 \\le x < 1.1\\\\\n0 & \\text{ wenn }x \\ge 1.1.\n\\end{array}\n\\right.\n$$\nDer Plot der Dichte zeigt, dass die Realisation der Zufallsvariable $X$\nmit Sicherheit in dem Intervall\n$[-0.56, 1.1]$ liegen wird. Es ist eher unwahrscheinlich, dass ein Wert\nsehr nah an der rechten Grenzen realisiert wird. Auch der Bereich\num die 0 herum ist etwas weniger wahrscheinlich als die Bereiche\num die 0.75 herum oder nah an der linken Grenze.\n```{r}\n#| code-fold: true\n#| code-summary: \"R-Code zeigen\"\nx <- c(-1, -0.56, NA,\n       seq(-0.56, 1.1, length=100),\n       NA, 1.1, 1.8)\n\nf <- 0.5-x^4+x^2\nf[c(1, 2, 105, 106)] <- 0\n\nplot(x, f, t=\"l\", lwd=3,\n     xlab=\"x\", ylab=\"f(x)\",\n     main=\"Dichte\")\n```\nWie hoch ist die Wahrscheinlichkeit, dass die Zufallsvariable $X$\nin dem Intervall $[0.1,0.8]$ liegt? Um diese Frage zu beantworten,\nberechnen wir das Integral\n$$\n\\begin{align*}\n\\int_{0.1}^{0.8} f(x)dx&=\\int_{0.1}^{0.8} (-x^4+x^2+0.5) dx\\\\\n&= \\left. -\\frac{1}{5}x^5+\\frac{1}{3}x^3+\\frac{1}{2}x \\right|_{0.1}^{0.8}\\\\[2ex]\n&= 0.4548.\n\\end{align*}\n$$\nDie Verteilungsfunktion erhält man durch Integration der Dichte.\n$$\nF(x)=\\left\\{\n\\begin{array}{ll}\n0 & \\text{ wenn }x < -0.56\\\\\n-\\frac{1}{5}x^5+\\frac{1}{3}x^3+\\frac{1}{2}x+0.3275 & \\text{ wenn }-0.56 \\le x < 1.1\\\\\n1 & \\text{ wenn }x \\ge 1.1.\n\\end{array}\n\\right.\n$$\nDie Konstante (0.3275) muss so gewählt werden, dass die Verteilungsfunktion\nam Punkt -0.56 bei 0 startet und am Punkt 1.1 bei 1 endet. Der Plot der\nVerteilungsfunktion macht deutlich, dass Verteilungsfunktionen für\ndas schnelle Erfassen der Eigenschaften einer Verteilung nicht so gut\ngeeignet sind wie Dichtefunktionen. Die Realisation der Zufallsvariable liegt\nmit höherer Wahrscheinlichkeit in einem Bereich, in dem die Verteilungsfunktion\nsteil ist, als in einem Bereich, in dem sie flacher verläuft. Bereiche,\nin denen die Verteilungsfunktion gar nicht ansteigt, gehören nicht zum\nTräger der Zufallsvariable.\n```{r}\n#| code-fold: true\n#| code-summary: \"R-Code zeigen\"\nx <- c(-1, -0.56, \n       seq(-0.56, 1.1, length=100),\n       1.1, 1.8)\nf <- x^3/3-x^5/5+x/2+0.3275\n\nf[1:2] <- 0\nf[103:104] <- 1\n\nplot(x, f, t=\"l\", lwd=3,\n     xlab=\"x\", ylab=\"F(x)\",\n     main=\"Verteilungsfunktion\")\n```\n:::\n\n## Numerische Integration {#sec-numintegration}\n\nNicht immer ist es möglich, Integrale in geschlossener Form \nzu berechnen. In manchen Fällen ist es vielleicht möglich, aber\nso mühsam, dass sich der Aufwand nicht lohnt, wenn eine\nApproximation des Ergebnisses ausreicht. In solchen\nFällen lassen sich die Integrale durch numerische Verfahren\nberechnen. Auch für die Plausibilitätskontrolle eines\nanalytischen Ergebnisses eignet sich die numerische Integration.\nDie numerische Mathematik liefert ausgefeilte Algorithmen für \ndie numerische Integration. In diesem Kurs lernen Sie nur eine\n\"Holzhammer-Methode\" kennen, mit der Sie eine grobe Approximation\neines Integrals schnell und einfach bestimmen können. \n\nDas Integral einer Funktion $f(x)$ von $a$ bis $b$ ist die Fläche \nzwischen der Funktion und der x-Achse,\n$$\n\\int_a^b f(x)dx.\n$$\n\nDie Fläche lässt sich annähern, indem man viele schmale Rechtecke in \ndie Funktion einschmiegt. Die Graphik illustriert das beispielhaft\nfür das Integral von 0.1 bis 0.8 der Dichtefunktion\n$$\nf(x)=0.5-x^4+x^2.\n$$\n\n```{r}\n#| code-fold: true\n#| code-summary: \"R-Code zeigen\"\nx <- c(-1, -0.56, NA,\n       seq(-0.56, 1.1, length=100),\n       NA, 1.1, 1.8)\n\nf <- function(x){\n  return(0.5-x^4+x^2)\n}\n\nff <- f(x)\nff[c(1, 2, 105, 106)] <- 0\n\nplot(x, ff, t=\"l\", lwd=3,\n     xlab=\"x\", ylab=\"f(x)\",\n     main=\"Approximation des Integrals\")\n\nabline(h=0)\ndx <- 0.05\n\ng <- seq(0.1,0.8,by=dx)\nfor(i in 1:(length(g)-1)){\n  lines(c(g[i], g[i], g[i]+dx, g[i]+dx),\n        c(0, f(g[i]), f(g[i]), 0))\n}\n```\nDie Fläche der Rechtecke lässt sich sehr leicht bestimmen, selbst wenn es \nviele sind. Wenn die Gitterpunkte zwischen $a$ und $b$ mit $x_1,\\ldots,x_R$\nbezeichnet werden und der Abstand zwischen zwei benachbarten Gitterpunkten\nmit $\\Delta$, dann ist die gesamte Fläche aller Rechtecke\n$$\n\\sum_{i=1}^R f(x_i)\\Delta.\n$$\nJe feiner die Rechtecke (d.h. je größer $R$ bzw. je kleiner $\\Delta$) sind, \ndesto genauer wird das Integral approximiert. Die Breite der Rechtecke\nentspricht (im Grenzwert) dem Symbol $dx$ des Integrals.\n\nDiese Berechnung kann wie folgt in R umgesetzt werden. \nZuerst wird ein feines Gitter von $a=0.1$ bis $b=0.8$ erzeugt. Die Gitterpunkte\nwerden in einem Vektor `x` abgelegt. Der Vektor wird durch die Funktion\n`seq` erzeugt (s. @sec-vektoren). Dabei können Sie entweder mit der Option `length`\ndie Anzahl der Gitterpunkte festlegen oder alternativ mit der Option `by` den\nAbstand der Gitterpunkte voneinander vorgeben. In dem folgenden Code\nwird der Abstand vorgegeben und mit `dx` bezeichnet, um die Analogie\nzum Integral deutlich zu machen.\n```{r}\ndx <- 0.001\nx <- seq(from=0.1, to=0.8, by=dx)\n```\nNun werden die Funktionwerte an allen Gitterpunkten `x` ermittelt und\nin dem Vektor `f` gespeichert. Da R vektor-orientiert arbeitet, geschieht\ndas sehr einfach mit einem einzigen Befehl.\n```{r}\nf <- 0.5 - x^4 + x^2\n```\nDer Wert des Integrals kann nun angenähert werden durch\n```{r}\nsum(f*dx)\n```\nDer analytisch hergeleitete Wert des Integrals beträgt 0.4548. \nDer Fehler der numerischen Approximation ist also sehr klein.\n\n## Quantilfunktion\n\nDie Quantilfunktion ist das Gegenstück zur Verteilungsfunktion. Während die\nVerteilungsfunktion auf die Frage antwortet \"Wie hoch ist die Wahrscheinlichkeit,\ndass die Zufallsvariable den Wert $x$ nicht übersteigt?\", beantwortet die\nQuantilfunktion die Frage \"Welcher Wert wird mit einer Wahrscheinlichkeit von \n$p$ nicht überschritten?\". Da es einige Fälle gibt, in denen diese Frage\nnicht eindeutig beantwortet werden kann, ist die formale Definition der\nQuantilfunktion etwas komplizierter:\n\n::: callout-note\n## Definition: Quantilfunktion\n\nDie Funktion\n$$\nF_X^{-1}(p)=\\min\\{x:F_X(x)\\ge p\\}\n$$\nheißt **Quantilfunktion** von $X$. Der Wert $x_p=F_X^{-1}(p)$ \nheißt **p-Quantil** von $X$. Der Definitionsbereich ist $0<p<1$\n(also ohne die Intervallgrenzen).\n:::\n\nDen Subindex kann man weglassen, wenn sich die Zufallsvariable \naus dem Kontext ergibt. Gelegentlich findet man auch die \nalternative Notation $Q_X(p)$ oder $Q(p)$ für die Quantilfunktion.\nDas 0.5-Quantil heißt auch **Median** (engl. median).\n\nAus einer gegebenen Verteilungsfunktion lässt sich die Quantilfunktion\ndurch Invertieren finden. Das geht leicht, wenn die Verteilungsfunktion\nstreng monoton steigend verläuft. Aufpassen muss man jedoch, wenn\nsie Sprünge aufweist oder in einigen Bereichen flach verläuft.\n\n::: { .callout-tip collapse=\"true\"}\n## Beispiel: Anzahl der Sechsen bei zwei Würfeln\n\nZwei Würfel werden geworfen. Die Zufallsvariable $X$ sei die Anzahl\nder Sechsen. Die Verteilungsfunktion ist eine Treppenfunktion\nmit den Sprungstellen 0, 1 und 2, die hier noch einmal \ngezeigt wird. \n```{r}\n#| code-fold: true\n#| code-summary: \"R-Code zeigen\"\nx <- c(0, 1, 2)\ny <- c(0, 25/36, 35/36, 1)\n\nplot(stepfun(x, y),\n     verticals=FALSE, \n     pch=19,\n     xlab=\"x\",\n     ylab=\"F(x)\",\n     main=\"Verteilungsfunktion\")\n```\nWie sieht die zugehörige Quantilfunktion aus? Um das zu beantworten,\nwandern wir langsam die y-Achse hoch und schauen jeweils, welches \nQuantil zu dem Wert gehört. Für Werte von $0<p\\le 25/36$ landet man\nauf dem Quantil 0. Für $25/36<p\\le 35/36$ ergibt sich das Quantil\n1 und für $p>35/36$ ist das Quantil 2. Also ist\n$$\nF^{-1}(p)=\\left\\{\n\\begin{array}{ll}\n0 & \\text{ wenn }0 < p \\le 25/36\\\\\n1 & \\text{ wenn }25/36 < p \\le 35/36\\\\\n2 & \\text{ wenn }p>35/36\n\\end{array}\n\\right.\n$$\nbzw. als Grafik\n```{r}\n#| code-fold: true\n#| code-summary: \"R-Code zeigen\"\np <- c(0, 25/36, 35/36, 1)\nQ <- c(0, 1, 2)\n\nplot(p[1:2], Q[c(1,1)],\n     t=\"l\",\n     xlab=\"x\",\n     ylab=\"F(x)\",\n     xlim=c(0,1),\n     ylim=c(0,2),\n     main=\"Quantilfunktion\")\n\nfor(i in 2:length(Q)){\n  lines(p[c(i,i+1)], Q[c(i,i)])\n}\npoints(p[2:3], Q[1:2], pch=19)\n```\n:::\n\nIm Gegensatz zur Verteilungsfunktion ist die Quantilfunktion nicht\nrechtsstetig, sondern linksstetig. Der Funktionswert an einer Sprungstelle\nist gleich dem Grenzwert, wenn man sich von links der Sprungstelle nähert.\n\n::: { .callout-tip collapse=\"true\"}\n## Beispiel: Quantilfunktion einer stetigen Zufallsvariable\n\nWir betrachten die Zufallsvariable $X$ mit der Verteilungsfunktion\n$$\nF(x)=\\left\\{\n\\begin{array}{ll}\n0 & \\text{ wenn }x\\le 1\\\\\n(x-1)^2 & \\text{ wenn }1< x\\le 2\\\\\n1 & \\text{ wenn }x>2\\\\\n\\end{array}\n\\right.\n$$\nZum Invertieren der Verteilungsfunktion reicht es aus,\ndas Intervall $[1,2]$ zu betrachten, weil die Werte 0 und\n1 nicht im Definitionsbereich der Quantilfunktion liegen.\nZum Invertieren setzt man die Verteilungsfunktion auf \nden Wert $p$ und löst dann nach $x$ auf.\n$$\n\\begin{align*}\n&&F(x) &= p \\\\\n\\Leftrightarrow&& (x-1)^2 &= p\\\\\n\\Leftrightarrow&& x-1 &= \\sqrt{p}\\\\\n\\Leftrightarrow&& x &= 1+\\sqrt{p}\n\\end{align*}\n$$\nFolglich lautet die Quantilfunktion\n$$\nF^{-1}(p)=1+\\sqrt{p}.\n$$\n:::\n\n## Erwartungswert {#sec-erwartungswert}\n\nDer Erwartungswert einer Verteilung gibt Auskunft darüber, wo der\n\"Schwerpunkt\" der Verteilung liegt. \n\n::: callout-note\n## Definition: Erwartungswert\n\nDer **Erwartungswert** (engl. expectation) einer Zufallsvariable ist\n$$\nE(X)=\\left\\{\n\\begin{array}{ll}\n\\sum\\limits_{j: x_j\\in T_X} x_j f(x_j) & \\text{ wenn } X\\text{ diskret}\\\\[2ex]\n\\int\\limits_{-\\infty}^\\infty x f(x)dx & \\text{ wenn }X\\text{ stetig}\n\\end{array}\n\\right.\n$$\n:::\n\nBeachten Sie, dass der Erwartungswert einer Zufallsvariablen\nkeine Zufallsvariable, sondern eine reelle Zahl ist. Wir werden \nspäter in @sec-lln sehen, dass der Erwartungswert derjenige Wert\nist, gegen den der Durchschnitt von sehr vielen Realisierungen\nder Zufallsvariable (in einem gewissen Sinn) konvergiert. Wirft\nman z.B. einen Würfel sehr oft (eigentlich unendlich oft), dann ergibt \nsich als Durchschnitt der (unendlich) vielen Realisationen \nder Erwartungswert.\n\nWie der Erwartungswert einer Zufallsvariable berechnet wird, hängt \ndavon ab, ob es sich um eine diskrete oder eine stetige Zufallsvariable\nhandelt. \n\n::: { .callout-tip collapse=\"true\"}\n## Beispiel: Erwartungswert einer diskreten Zufallsvariable\n\nZwei Würfel werden geworfen. Die Zufallsvariable $X$ sei die Anzahl\nder Sechsen. Wie hoch ist der Erwartungswert von $X$? Für die\nBerechnung benötigt man die Wahrscheinlichkeitsfunktion\n$$\nf(x)=\\left\\{\n\\begin{array}{ll}\n25/36 & \\text{ wenn }x=0\\\\\n10/36 & \\text{ wenn }x=1\\\\\n1/36 & \\text{ wenn }x=2\\\\\n0 & \\text{ sonst.}\n\\end{array}\n\\right.\n$$\nDer Erwartungswert ist \n$$\nE(X)=0\\cdot\\frac{25}{36}+1\\cdot\\frac{10}{36}+2\\cdot\\frac{1}{36}=\\frac{1}{3}.\n$$\n:::\n\n::: { .callout-tip collapse=\"true\"}\n## Beispiel: Erwartungswert einer stetigen Zufallsvariable\n\nDie Dichte der stetigen Zufallsvariable $X$ sei \n$$\nf(x)=\\left\\{\n\\begin{array}{ll}\n0 & \\text{ wenn }x < -0.56\\\\\n-x^4+x^2+0.5 & \\text{ wenn }-0.56 \\le x < 1.1\\\\\n0 & \\text{ wenn }x \\ge 1.1.\n\\end{array}\n\\right.\n$$\nDer Erwartungswert dieser Zufallsvariable beträgt\n$$\n\\begin{align*}\nE(X) &= \\int_{-\\infty}^\\infty x f(x) dx\\\\\n&=\\int_{-0.56}^{1.1} x f(x) dx\\\\\n&=\\int_{-0.56}^{1.1} x (x^2-x^4+0.5) dx\\\\\n&=\\int_{-0.56}^{1.1} (x^3-x^5+0.5x) dx\\\\\n&=\\left. \\frac{1}{4}x^4-\\frac{1}{6}x^6+\\frac{1}{4}x^2 \\right|_{-0.56}^{1.1}\\\\\n&=0.3732-0.0978\\\\[1ex]\n&=0.2754.\n\\end{align*}\n$$\nDer Erwartungswert einer stetige Zufallsvariable ist ein Integral.\nEs ist daher auch möglich, den Erwartungswert in R numerisch \nzu approximieren. Die Vorgehensweise ist analog zu @sec-numintegration:\nZuerst definiert man ein feines Gitter über dem relevanten\nBereich. Für den Erwartungswert ist der relevante Bereich der\ngesamte Träger, also für $X$ das Intervall $[-0.56,1.1]$.\n```{r}\ndx <- 0.001\nx <- seq(-0.56, 1.1, by=dx)\n```\nNun wird der Funktionswert an allen Gitterpunkten bestimmt.\n```{r}\nf <- -x^4+x^2+0.5\n```\nDie numerische Approximation des Erwartungswerts ist\n```{r}\nsum(x*f*dx)\n```\nDie Abweichung vom analytisch hergeleiteten Wert ist\nsehr gering.\n:::\n\n## Varianz {#sec-varianz}\n\nDie Varianz einer Zufallsvariable gibt an, wie stark die Verteilung \nstreut bzw. wie sehr man mit großen Abweichungen vom Erwartungswert\nrechnen sollte.\n\n::: callout-note\n## Definition: Varianz und Standardabweichung\n\nDer **Varianz** (engl. variance) einer Zufallsvariable ist\n$$\nVar(X)=E\\left[(X-E(X))^2\\right].\n$$\nDie (positive) Wurzel aus der Varianz nennt man Standardabweichung\n(engl. standard deviation).\n:::\n\nEbenso wie der Erwartungswert ist auch die Varianz einer\nZufallsvariable eine reelle Zahl.\nFür diskrete und stetige Zufallsvariablen lässt sich die Varianz\nfolgendermaßen schreiben:\n$$\nVar(X)=\\left\\{\n\\begin{array}{ll}\n\\sum\\limits_{j:x_j\\in T_X} (x_j-E(X))^2 f(x_j) & \\text{ wenn } X\\text{ diskret}\\\\[2ex]\n\\int\\limits_{-\\infty}^\\infty (x-E(X))^2 f(x)dx & \\text{ wenn } X\\text{ stetig}\n\\end{array}\n\\right.\n$$\n\nFür die Berechnung der Varianz ist manchmal die folgende Formel hilfreich:\n$$\nVar(X)=E(X^2)-(E(X))^2.\n$$\n\n::: { .callout-tip collapse=\"true\"}\n## Beispiel: Varianz einer diskreten Zufallsvariablen\n\nZwei Würfel werden geworfen. Die Zufallsvariable $X$ sei die Anzahl\nder Sechsen. Wie hoch ist die Varianz von $X$? Für die Berechnung nutzen\nwir den Streuungsverschiebungssatz. Der Erwartungswert von $X^2$ wird\nanalog zum Erwartungswert berechnet. Es ergibt sich\n$$\n\\begin{align*}\nE(X^2)&=\\sum_{j:x_j\\in T_X} x_j^2f(x_j)\\\\\n&=0^2\\cdot\\frac{25}{36}+1^2\\cdot\\frac{10}{36}+2^2\\cdot\\frac{1}{36}=\\frac{7}{18}.\n\\end{align*}\n$$\nDer Erwartungswert $E(X)$ wurde bereits im vorherigen Abschnitt berechnet,\nnämlich $E(X)=1/3$. Die Varianz ist folglich\n$$\n\\begin{align*}\nVar(X) &= E(X^2)-(E(X))^2\\\\\n&=\\frac{7}{18}-\\frac{1}{9}\\\\\n&= \\frac{5}{18}.\n\\end{align*}\n$$\n:::\n\n::: { .callout-tip collapse=\"true\"}\n## Beispiel: Varianz einer stetigen Zufallsvariablen\n\nAuch für die Berechnung der Varianz einer stetigen Zufallsvariable nutzen\nwir den Streuungsverschiebungssatz. Die Dichte der stetigen Zufallsvariable $X$ \nsei \n$$\nf(x)=\\left\\{\n\\begin{array}{ll}\n0 & \\text{ wenn }x < -0.56\\\\\nx^2-x^4+0.5 & \\text{ wenn }-0.56 \\le x < 1.1\\\\\n0 & \\text{ wenn }x \\ge 1.1.\n\\end{array}\n\\right.\n$$\nDer Erwartungswert von $X^2$ beträgt\n$$\n\\begin{align*}\nE(X^2) &= \\int_{-\\infty}^\\infty x^2f(x)dx\\\\\n&=\\int_{-0.56}^{1.1} x^2 (-x^4+x^2+0.5)dx\\\\\n&=\\int_{-0.56}^{1.1} (-x^6+x^4+0.5x^2)dx\\\\\n&=\\int_{-0.56}^{1.1} (-x^6+x^4+0.5x^2)dx\\\\\n&=\\left. -\\frac{1}{7}x^7+\\frac{1}{5}x^5+\\frac{1}{6}x^3 \\right|_{-0.56}^{1.1}\\\\\n&=0.2655-(-0.0378)\\\\[1ex]\n&=0.3033.\n\\end{align*}\n$$\nDer Erwartungswert von $X$ wurde bereits im letzten Abschnitt berechnet,\nund zwar $E(X)=0.2754$. Damit ergibt sich die Varianz als\n$$\n\\begin{align*}\nVar(X) &= E(X^2)-(E(X))^2\\\\\n&=0.3033-0.2754^2\\\\\n&= 0.2275.\n\\end{align*}\n$$\nSo wie der Erwartungswert kann auch die Varianz numerisch\napproximiert werden, denn auch die Varianz einer stetigen\nZufallsvariable ist letztlich ein Integral. Wir nutzen\nwieder das Gitter\n```{r}\ndx <- 0.001\nx <- seq(-0.56, 1.1, by=dx)\n```\nund berechnen den Funktionswert an allen Gitterpunkten.\n```{r}\nf <- -x^4 + x^2 + 0.5\n```\nDie numerische Approximation der Varianz ist\n```{r}\nsum((x-0.2754)^2 * f * dx)\n```\noder alternativ, wenn man den Verschiebungssatz anwendet,\n```{r}\nsum(x^2 * f * dx) - 0.2754^2\n```\nDabei wurde das Ergebnis für den Erwartungswert (gerundet 0.2754)\nübernommen. Die Abweichung vom analytisch hergeleiteten Wert ist\nwiederum gering, wenn auch etwas höher als beim Erwartungswert.\n:::\n\n## Lineare Transformationen {#sec-lintrans}\n\nEine lineare Transformation einer Zufallsvariable ergibt wieder eine\nZufallsvariable. Für zwei reelle Zahlen $a$ und $b$ ist\n$$\nY=aX+b\n$$\neine lineare Transformation von $X$. Welche Eigenschaften hat die\ntransformierte Zufallsvariable $Y$? Wir sehen uns an, wie sich die\nTransformation auf die Verteilungsfunktion, den Erwartungswert und die\nVarianz auswirkt.\n\nDie Verteilungsfunktion von $Y$ ist für $a>0$\n$$\n\\begin{align*}\nF_Y(y) &= P(Y\\le y)\\\\\n&= P(aX+b \\le y)\\\\\n&= P(aX \\le y-b)\\\\\n&= P\\left(X \\le \\frac{y-b}{a}\\right)\\\\\n&= F_X\\left(\\frac{y-b}{a}\\right).\n\\end{align*}\n$$\nFür $a<0$ dreht sich die Ungleichung bei der Division durch $a$ um, also gilt dann\n$$\n\\begin{align*}\nF_Y(y) &= P(Y\\le y)\\\\\n&= P(aX+b \\le y)\\\\\n&= P(aX \\le y-b)\\\\\n&= P\\left(X \\ge \\frac{y-b}{a}\\right)\\\\\n&= 1-P\\left(X <\\frac{y-b}{a}\\right).\n\\end{align*}\n$$\nWie die Beziehung des letzten Terms zur Verteilungsfunktion von $X$ aussieht,\nlässt sich nicht einfach allgemein beantworten. Wenn $X$ stetig verteilt ist,\nmacht es keinen Unterschied, ob in der Ungleichung ein \"$<$\" oder ein \"$\\le$\"\nsteht, dann ist also\n$$\nF_Y(y)=1-F_X\\left(\\frac{y-b}{a}\\right).\n$$\nWie wirkt sich eine lineare Transformation $Y=aX+b$ auf den Erwartungswert aus?\nWir untersuchen diskrete und stetige Zufallsvariablen getrennt voneinander.\nZuerst betrachten wir eine diskrete Zufallsvariable $X$ und $a,b\\in\\mathbb{R}$.\nDer Erwartungswert von $Y$ ist\n$$\n\\begin{align*}\nE(Y) &= E(aX+b)\\\\\n&= \\sum_{j\\in T_X}(ax_j+b)f(x_j)\\\\\n&= \\sum_{j\\in T_X}ax_j f(x_j) + \\sum_{j\\in T_X}b f(x_j)\\\\\n&= a\\sum_{j\\in T_X}x_j f(x_j) + b\\sum_{j\\in T_X}f(x_j)\\\\\n&= aE(X)+b,\n\\end{align*}\n$$\ndenn $\\sum_{j\\in T_X}f(x_j)=1$. Wenn $X$ eine stetige Zufallsvariable ist,\ndann gilt für den Erwartungswert der linearen Transformation\n$$\n\\begin{align*}\nE(Y) &= E(aX+b)\\\\\n&= \\int_{-\\infty}^\\infty (ax+b)f(x)dx\\\\\n&= \\int_{-\\infty}^\\infty ax f(x)dx + \\int_{-\\infty}^\\infty b f(x)dx\\\\\n&= a\\int_{-\\infty}^\\infty x f(x)dx + b\\int_{-\\infty}^\\infty f(x)dx\\\\\n&= aE(X)+b,\n\\end{align*}\n$$\nweil $\\int_{-\\infty}^\\infty f(x)dx=1$.\n\nEs gilt also sowohl für diskrete als auch für stetige Zufallsvariablen, \ndass der Erwartungswert der linearen Transformation der Zufallsvariable\nder linearen Transformation des Erwartungswerts entspricht. Kurz gesagt,\nkann man den Erwartungswert in eine lineare Funktion \"hineinziehen\"\noder ihn aus ihr \"herausziehen\". Man sagt auch, dass der Erwartungswert\nein \"linearer Operator\" ist.\n\n<img src=\"images/AdobeStock_458950051b_AttentionSign.jpeg\" align=\"right\" width=10%\" style=\"padding-left:15px;padding-top:5px;\"/>\n**Achtung**: Den Erwartungswert darf man im allgemeinen nicht aus anderen\n(nichtlinearen) Funktionen herausziehen oder ihn dort hineinziehen.\nSo ist beispielsweise im allgemeinen\n$$\nE(X^2) \\neq E(X)^2.\n$$\nDie Ergebnisse zum Erwartungswert können wir nun benutzen, um die\nVarianz einer linear transformierten Zufallsvariable zu untersuchen.\nEs gilt\n$$\n\\begin{align*}\nVar(Y) &= E((Y-E(Y))^2)\\\\\n&= E((aX+b-E(aX+b))^2)\\\\\n&= E((aX+b-(aE(X)+b))^2)\\\\\n&= E((aX+b-aE(X)-b)^2)\\\\\n&= E((aX-aE(X))^2)\\\\\n&= E(a^2(X-E(X))^2)\\\\\n&= a^2 E((X-E(X))^2)\\\\\n&= a^2 Var(X).\n\\end{align*}\n$$\nDiese Herleitung gilt sowohl für diskrete als auch für stetige Zufallsvariablen.\nOffensichtlich wirkt sich eine additive Verschiebung um $b$ überhaupt nicht\nauf die Varianz aus. Eine Multiplikation mit $a$ verändert die Varianz jedoch,\nund zwar um den Faktor $a^2$. Wenn $a>1$ ist, wird die Varianz also größer,\nwenn $0<a<1$ ist, wird sie kleiner. Beachten Sie, dass es für die Varianz\nkeine Rolle spielt, ob $a$ positiv oder negativ ist. Insbesondere bleibt die\nVarianz unverändert, wenn $X$ mit $(-1)$ multipliziert wird.\n\n## Standardisierung {#sec-standardisierung}\n\n<img src=\"images/AdobeStock_13508641b_Gurken.jpeg\" align=\"right\" width=40%\" style=\"padding-left:15px;padding-top:5px;\"/>\nEine lineare Transformation, die dazu führt, dass der Erwartungswert der\ntransformierten Zufallsvariable 0 und die Varianz 1 ist, nennt man \n**Standardisierung**. Die transformierte Zufallsvariable heißt \nstandardisiert. Vergleicht man zwei standardisierte Zufallsvariablen\nmiteinander, dann wird sowohl die Lage (Erwartungswert) als auch\ndie Streuung (Varianz) beim Vergleich ausgeblendet. \nWelche lineare Transformation muss für eine\nStandardisierung durchgeführt werden? Wie erreicht man, dass der \nErwartungswert nach der Transformation 0 ist und die Varianz 1?\nWir gehen in zwei Schritten vor. Im ersten Schritt subtrahieren wir von der\nZufallsvariablen $X$ ihren Erwartungswert $E(X)$ (also eine reelle Zahl),\n$$\nX-E(X).\n$$\nDie Zufallsvariable $X-E(X)$ hat den Erwartungswert\n$$\nE(X-E(X))=E(X)-E(X)=0.\n$$\nDie Varianz von $X-E(X)$ ist gleich der Varianz von $X$, denn die Varianz\nverändert sich nicht, wenn eine reelle Zahl addiert oder subtrahiert wird. \nDer Erwartungswert ist eine reelle Zahl. Man nennt die Zufallsvariable\n$X-E(X)$ auch **zentriert**.\n\nIm zweiten Schritt dividieren wir $X-E(X)$ durch die Standardabweichung von\n$X$,\n$$\n\\frac{X-E(X)}{\\sqrt{Var(X)}}.\n$$\nDadurch verändert sich der Erwartungswert nicht, er bleibt weiterhin 0. Wie\ngroß ist die Varianz? Um das zu beantworten, nutzen wir die Ergebisse zu\nVarianzen von linearen Transformationen, insb. das Ergebnis, dass eine multiplikative\nKonstante aus der Varianz herausgezogen werden kann, dann aber ins Quadrat\ngesetzt werden muss. Also ergibt sich\n$$\nVar\\left(\n\\frac{X-E(X)}{\\sqrt{Var(X)}}\n\\right)=\n\\frac{1}{Var(X)}Var(X-E(X))=1.\n$$\nIm letzten Schritt wird ausgenutzt, dass der Erwartungswert eine\nreelle Zahl ist, so dass $X-E(X)$ nur eine Verschiebung der\nZufallsvariable ist. Das hat keinen Einfluss auf die Varianz, sie\nist weiterhin $Var(X)$. Fassen wir zusammen: Wenn $X$ eine Zufallsvariable mit Erwartungswert $E(X)$\nund Varianz $Var(X)$ ist, dann hat die linear transformierte Zufallsvariable\n$$\nY=\\frac{X-E(X)}{\\sqrt{Var(X)}}\n$$\nden Erwartungswert $E(Y)=0$ und die Varianz $Var(Y)=1$. In der Schreibweise\ndes vorhergehenden Abschnitts erreicht man eine Standardisierung von $X$ durch\ndie lineare Transformation $Y=aX+b$ mit $a=1/\\sqrt{Var(X)}$ und\n$b=E(X)/\\sqrt{Var(X)}$.\n\n","srcMarkdownNoYaml":""},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["styles.css"],"output-file":"03-zufallsvariablen.html"},"language":{"toc-title-document":"Inhaltsverzeichnis","toc-title-website":"Auf dieser Seite","related-formats-title":"Andere Formate","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Quelle","section-title-abstract":"Zusammenfassung","section-title-appendices":"Anhang","section-title-footnotes":"Fußnoten","section-title-references":"Literatur","section-title-reuse":"Wiederverwendung","section-title-copyright":"Urheberrechte","section-title-citation":"Zitat","appendix-attribution-cite-as":"Bitte zitieren Sie diese Arbeit als:","appendix-attribution-bibtex":"Mit BibTeX zitieren:","title-block-author-single":"Autor","title-block-author-plural":"Authors","title-block-affiliation-single":"Zugehörigkeit","title-block-affiliation-plural":"Zugehörigkeiten","title-block-published":"Veröffentlicht am","title-block-modified":"Geändert","callout-tip-title":"Beispiel","callout-note-title":"Definition","callout-warning-title":"Warnung","callout-important-title":"Wichtig","callout-caution-title":"Vorsicht","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Gesamten Code zeigen","code-tools-hide-all-code":"Gesamten Code verbergen","code-tools-view-source":"Quellcode anzeigen","code-tools-source-code":"Quellcode","code-line":"Zeile","code-lines":"Zeilen","copy-button-tooltip":"In die Zwischenablage kopieren","copy-button-tooltip-success":"Kopiert","repo-action-links-edit":"Seite editieren","repo-action-links-source":"Quellcode anzeigen","repo-action-links-issue":"Problem melden","back-to-top":"Zurück nach oben","search-no-results-text":"Keine Treffer","search-matching-documents-text":"Treffer","search-copy-link-title":"Link in die Suche kopieren","search-hide-matches-text":"Zusätzliche Treffer verbergen","search-more-match-text":"weitere Treffer in diesem Dokument","search-more-matches-text":"weitere Treffer in diesem Dokument","search-clear-button-title":"Zurücksetzen","search-detached-cancel-button-title":"Abbrechen","search-submit-button-title":"Abschicken","search":"Search","toggle-section":"Abschnitt umschalten","toggle-sidebar":"Seitenleiste umschalten","toggle-dark-mode":"Dunkelmodus umschalten","toggle-reader-mode":"Lesemodus umschalten","toggle-navigation":"Navigation umschalten","crossref-fig-title":"Abbildung","crossref-tbl-title":"Tabelle","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Korollar","crossref-prp-title":"Aussage","crossref-cnj-title":"Annahme","crossref-def-title":"Definition","crossref-exm-title":"Beispiel","crossref-exr-title":"Übungsaufgabe","crossref-ch-prefix":"Kapitel","crossref-apx-prefix":"Anhang","crossref-sec-prefix":"Kapitel","crossref-eq-prefix":"Gleichung","crossref-lof-title":"Abbildungsverzeichnis","crossref-lot-title":"Tabellenverzeichnis","crossref-lol-title":"Listingverzeichnis","environment-proof-title":"Beweis","environment-remark-title":"Anmerkung","environment-solution-title":"Lösung","listing-page-order-by":"Sortieren nach","listing-page-order-by-default":"Voreinstellung","listing-page-order-by-date-asc":"Datum (aufsteigend)","listing-page-order-by-date-desc":"Neueste","listing-page-order-by-number-desc":"Absteigend","listing-page-order-by-number-asc":"Aufsteigend","listing-page-field-date":"Datum","listing-page-field-title":"Titel","listing-page-field-description":"Beschreibung","listing-page-field-author":"Autor:in","listing-page-field-filename":"Dateiname","listing-page-field-filemodified":"Geändert","listing-page-field-subtitle":"Untertitel","listing-page-field-readingtime":"Lesezeit","listing-page-field-categories":"Kategorien","listing-page-minutes-compact":"{0} min","listing-page-category-all":"alle","listing-page-no-matches":"Keine Treffer"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.353","editor":"source","callout-icon":false,"other-links-title":"Weitere Links","code-links-title":"Code-Links","launch-dev-container-title":"Dev Container starten","launch-binder-title":"Binder starten","title-block-keywords":"Schlüsselwörter","search-label":"Suchen","listing-page-field-wordcount":"Wortanzahl","listing-page-words":"{0} Wörter","theme":"sandstone"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}
=======
{"title":"Zufallsvariablen","markdown":{"headingText":"Zufallsvariablen","headingAttr":{"id":"zufallsvariablen","classes":[],"keyvalue":[]},"containsRefs":false,"markdown":"\nDie wichtigsten formalen Grundlagen der Wahrscheinlichkeitstheorie sind nun gelegt. Darauf aufbauend definieren wir Zufallsvariablen. Zufallsvariablen sind - intuitiv gesprochen - Zahlen, deren Wert man noch nicht kennt, deren Wert sich aber (irgendwann) realisiert. Die formale Definition von Zufallsvariablen bezieht sich auf die Ergebnismenge.\n\n::: callout-note\nEine Abbildung \n$$\nX: \\Omega\\rightarrow \\mathbb{R}\n$$ \nheißt **Zufallsvariable** (engl. random variable).\n:::\n\nEine Zufallsvariable kann man sich zwar als eine Zahl vorstellen, deren Wert man noch nicht kennt. Formal gesehen handelt es sich jedoch um eine Funktion, die jedem Element der Ergebnismenge genau eine reelle Zahl zuordnet.\n\n::: callout-tip\nAls Beispiel betrachten wir ein Zufallsexperiment, bei dem zwei Würfel geworfen\nwerden. Jeder der beiden Würfel zeigt dann 1, 2, 3, 4, 5 oder 6.\nDer Ergebnisraum hat folglich 36 Elemente, nämlich\n$$\n\\Omega=\\{11,12,13,14,15,16,21,22,23,\\ldots,65,66\\}.\n$$\nNun definieren wir eine Zufallsvariable $X$, die angibt, wie hoch die\nSumme der Augenzahlen ist. Offensichtlich kann es passieren, dass beide\nWürfel 1 zeigen, dann ist $X=2$. Wenn einer der Würfel eine 1 anzeigt,\nder andere eine 2, dann ist $X=3$ usw. Die Abbildung bzw. Funktion aus dem \nErgebnisraum in die Menge der reellen Zahlen sieht also so aus:\n$$\n\\begin{array}{lll}\n\\Omega && \\mathbb{R}\\\\\\hline\n11 & \\longrightarrow & 2\\\\\n12 & \\longrightarrow & 3\\\\\n13 & \\longrightarrow & 4\\\\\n14 & \\longrightarrow & 5\\\\\n15 & \\longrightarrow & 6\\\\\n16 & \\longrightarrow & 7\\\\\n21 & \\longrightarrow & 3\\\\\n22 & \\longrightarrow & 4\\\\\n23 & \\longrightarrow & 5\\\\\n\\vdots&&\\vdots\\\\\n65 & \\longrightarrow & 11\\\\\n66 & \\longrightarrow & 12\n\\end{array}\n$$\n:::\n\nWenn die Zufallsvariable sich realisiert, bezeichnet man die **Realisation** gewöhnlich mit einem Kleinbuchstaben. Beispielsweise ist $x$ die Realisation der Zufallsvariable $X$. Gedanklich ist es oft hilfreich, sich $X$ (also die Zufallsvariable) als die Situation ex ante und $x$ (also die Realisierung) als die Situation ex post vorzustellen.\n\nBeachten Sie den großen Unterschied zwischen einer Zufallsvariable und ihrer Realisation. Die Zufallsvariable ist eine Funktion, die Realisation ist eine reelle Zahl. Wahrscheinlichkeitsaussagen lassen sich nur über Zufallsvariablen treffen, nicht über ihre Realisation.\n\n::: callout-tip\nWir betrachten weiterhin das Zufallsexperiment mit zwei Würfeln. \nWie hoch ist die Wahrscheinlichkeit, dass die Zufallsvariable $X$: \"Summe\nder beiden Augenzahlen\" den Wert 4 annimmt? Um diese eigentlich sehr einfache\nFrage in dem formalen Rahmen sauber zu beantworten, müssen wir zunächst \nermitteln, welche Ergebnisse aus $\\Omega$ dazu führen, dass $X=4$ ist (das\nsogenannte Urbild von $X=4$).\n\nEs gibt drei Ergebnisse, die auf $X=4$ führen, nämlich $13,22$ und $31$. \nNun fragen wir uns, wie wahrscheinlich das Ereignis $\\{13,22,31\\}$ ist? Die\nAntwort ist einfach, weil es sich um ein Laplace-Experiment handelt,\n$$\nP(X=4)=P(\\{13,22,31\\})=\\frac{|(\\{13,22,31\\}|}{|\\Omega|}=\\frac{3}{36}=\\frac{1}{12}.\n$$\n:::\n\nUm mit Zufallsvorgängen in der Ökonomik zu arbeiten, sind Zufallsvariablen eine \ngroße Hilfe. Praktisch alle Vorgänge, bei denen der Zufall oder Unwissenheit \neine Rolle spielen, lassen sich gut mit Hilfe von Zufallsvariablen beschreiben. \nIn fast allen Fällen wird die Funktion\n$X:\\Omega\\to\\mathbb{R}$ nicht explizit angegeben, sondern implizit als\nvorhanden vorausgesetzt. Trotzdem ist es wichtig zu erkennen, dass \nZufallsvariablen quasi auf dem mengentheoretischen Fundament aufbauen, dass\nwir in den vorangegangenen Kapiteln gelegt haben.\n\n::: callout-tip\nMögliche Zufallsvariablen in der Ökonomik:\n\n- Die Zufallsvariable $X$ steht für den Gewinn einer Aktiengesellschaft im kommenden Jahr. Wenn das Jahr vergangen ist, hat sich der Gewinn $x$ realisiert. Von den ex ante vielen möglichen\nGewinnen hat sich nur einer tatsächlich eingestellt.\n\n- $X$ bezeichnet den Erwerbsstatus einer zufällig aus einer Population ausgewählten Person (0=nicht erwerbstätig, 1=Teilzeit, 2=Vollzeit). Sobald eine Person tatsächlich ausgewählt und befragt wurde, hat sich die Zufallsvariable realisiert und es ist dann entweder $x=0$ oder $x=1$\noder $x=2$..\n\n- $X$ ist das Nettomonatseinkommen eines zufällig ausgewählten Haushalts einer Population. Nachdem ein Haushalt zufällig ausgewählt und befragt wurde, hat sich die Zufallsvariable realisiert und ist zum Beispiel $x=3456$.\n\n- $X$ ist die Dauer, die ein technisches Gerät ohne Fehler funktioniert. Am\nStart des Geräts weiß man noch nicht, wie lange es fehlerfrei laufen wird.\nSobald ein Fehler auftritt, hat sich die Zufallsvariable realisiert. Die\nRealisation ist dann beispielsweise $x=12345$ Stunden.\n:::\n\n## Verteilungsfunktion\n\nWir wissen zwar nicht, welchen Wert eine Zufallsvariable annehmen wird, aber oft wissen wir, dass bestimmte Werte mit einer höheren Wahrscheinlichkeit vorkommen als andere Werte. So wissen wir zum Beispiel, dass beim Werfen mit zwei Würfeln die Augensumme 2 weniger wahrscheinlich ist als die Augensumme 7, denn für die Augensumme 2 müssen beide Würfel eine 1 zeigen, für die Augensumme 7 gibt es dagegen viel mehr Möglichkeiten (nämlich 16, 25, 34, 43, 52 und 61). Um die Verteilung einer Zufallsvariable zu beschreiben, gibt es mehrere Möglichkeiten. Eine besonders wichtige ist die Verteilungsfunktion.\n\n::: callout-note\nDie **Verteilungsfunktion** (engl. cumulative distributio function, cdf) einer Zufallsvariable $X$ gibt für $x\\in\\mathbb{R}$ die Wahrscheinlichkeit an, dass $X\\le x$ ist,\n$$\nF_X(x)=P(\\{\\omega: X(\\omega)\\le x\\})\n$$\noder in Kursschreibweise\n$$\nF_X(x)=P(X\\le x).\n$$\nWenn die Zufallsvariable sich aus dem Kontext erschließt, schreibt man auch\nanstelle von $F_X(x)$ einfach $F(x)$.\n:::\n\nDie Verteilungsfunktion einer Zufallsvariable ist sehr nützlich, weil durch sie die\nVerteilung der Zufallsvariable eindeutig charakterisiert wird. Kennt man die Verteiliungsfunktion,\ndann weiß man alles über die Vertelung, was wichtig ist.\n\nDie Verteilungsfunktion ist - wie der Name schon sagt - eine Funktion. Ihr\nDefinitionsbereich ist die Menge der reellen Zahlen $\\mathbb{R}$. Man darf also\njede beliebige Zahl in die Funktion einsetzen. Der Wertebereich der Verteilungsfunktion\nist das Intervall $[0,1]$, da es sich um eine Wahrscheinlichkeit handelt.\n\nVerteilungsfunktionen sind (wegen ihrer Konstruktion) immer monoton wachsend. Sie\nverlaufen niemals fallend, es kann jedoch sein, dass sie in einigen Bereichen \nflach verlaufen und nicht steigen. Verteilungsfunktionen können stetig sein,\nsie können aber auch Sprünge aufweisen.\n\nWenn man die Verteilungsfunktion $F_X(x)$ für immer kleinere Werte von $x$ auswertet,\ndann erreicht man (zumindest als Grenzwert) die 0, d.h.\n$$\n\\lim_{x\\to -\\infty} F_X(x)=0.\n$$\nFür immer größere Werte von $x$ erreicht man (zumindest als Grenzwert) die 1, d.h.\n$$\n\\lim_{x\\to\\infty} F_X(x)=1.\n$$\nAlle Verteilungsfunktionen sind monoton (aber nicht unbedingt streng monoton) \nwachsend. Für praktisch alle Anwendungen reicht es aus, sich auf zwei Klassen\nvon Verteilungsfunktionen einzuschränken. \n\n- Die eine Klasse sind Treppenfunktionen\n(Stufenfunktionen), d.h. die Verteilungsfunktion hat Sprünge und verläuft \nzwischen den Sprüngen waagerecht. Zufallsvariablen, die eine solche\nVerteilungsfunktion haben, nennt man diskrete Zufallsvariablen. \n\n- Die andere Klasse sind stetige Verteilungsfunktionen (d.h. ohne Sprünge).\nZufallsvariablen mit einer stetigen Verteilungsfunktion nennt man\nstetige Zufallsvariablen.\n\nIm folgenden wird genauer definiert, wann Zufallsvariablen diskret oder\nstetig sind und was für Eigenschaften diskrete und stetige\nZufallsvariablen haben.\n\n## Diskrete Zufallsvariablen\n\n::: callout-note\nEine Zufallsvariable heißt **diskret** (engl. discrete), wenn es \n\n- endliche viele Punkte $x_1, x_2,\\ldots, x_J$ oder\n- abzählbar unendlich viele Punkte $x_1, x_2,\\ldots$\n\ngibt mit der Eigenschaft \n$$\nP(X=x_j)>0\n$$\nfür alle $j$ und\n$$\n\\sum_j P(X=x_j)=1.\n$$\n:::\n\nOhne tiefer in die Mengenlehre einzusteigen, sei hier nur erwähnt, dass eine\nMenge abzählbar unendlich ist, wenn man ihre Elemente mit den natürlichen \nZahlen durchnummerieren kann. Abzählbar unendlich sind zum Beispiel die Menge\nder natürlichen Zahlen $\\mathbb{N}$, die Menge der ganzen Zahlen  $\\mathbb{Z}$ \nund die Menge aller Brüche $\\mathbb{B}$, nicht jedoch die Menge der\nreellen Zahlen  $\\mathbb{R}$ oder ein Intervall reeller Zahlen. Letztere\nnennt man überabzählbar unendlich.\n\nDie Menge aller Werte, die eine diskret verteilte Zufallsvariable annehmen kann, \nnennt man den Träger (engl. support) der Verteilung. Für endliche viele\nAusprägungen ist der Träger\n$$\nT_X=\\{x_1,\\ldots,x_J\\},\n$$\nund für (abzählbar) unendlich viele Ausprägungen ist er\n$$\nT_X=\\{x_1,x_2,x_3,\\ldots\\}.\n$$\nDie Funktion \n$$\nf(x)=\\left\\{\\begin{array}{ll}\np_j & \\text{ wenn }x=x_j\\\\\n0 &\\text{ sonst}\n\\end{array}\\right.\n$$\nheißt **Wahrscheinlichkeitsfunktion**. \n\nDie Verteilungsfunktion einer diskreten Zufallsvariable ist eine\nTreppenfunktion. Der Träger der Zufallsvariable gibt an, an welchen\nStellen die Treppenstufen liegen. Die erste Stufe ist an der Stelle $x_1$,\ndie zweite an der Stelle $x_2$ etc. Die Stufenhöhen sind $p_1, p_2,\\ldots,$.\n\nAn der folgenden Abbildung der Verteilungsfunktion einer Zufallsvariablen\n$X$ lässt sich also ablesen, dass $X$ diskret verteilt ist, dass $X$ den \nWert $x_1=0$ mit einer Wahrscheinlichkeit von 0.3 annimmt, den \nWert $x_2=3$ mit einer Wahrscheinlichkeit von 0.1, den Wert \n$x_3=4$ mit einer Wahrscheinlichkeit von 0.2 und den Wert $x_4=9$ mit\neiner Wahrscheinlichkeit von 0.4.\n\n```{r echo=FALSE}\nx <- c(0,3,4,9)\ny <- c(0,0.3,0.4,0.6,1)\nplot(stepfun(x,y),\n     verticals=FALSE, \n     pch=19,\n     xlab=\"x\",\n     ylab=\"F(x)\",\n     main=\"Verteilungsfunktion\")\n```\nDie Punkte zeigen, dass der Funktionswert an einer Sprungstelle immer\nder obere Wert ist. Man nennt die Treppenfunktion rechts-stetig, denn\nwenn man von der Sprungstelle ein winziges Stück nach rechts wandert, ändert\nsich der Funktionswert nicht. Wandert man ein winziges Stück nach links,\nspringt man auf die tiefere Stufe zurück.\n\n::: callout-tip\nZwei Würfel werden geworfen. Die Zufallsvariable $X$ sei die Anzahl\nder Sechsen. Sie kann also nur die Wert 0, 1 oder 2 annehmen\n(Träger). Die Wahrscheinlichkeitsfunktion ist\n$$\nf(x)=\\left\\{\n\\begin{array}{ll}\n25/36 & \\text{ für }x=0\\\\\n10/36 & \\text{ für }x=1\\\\\n1/36 & \\text{ für }x=2\\\\\n0 & \\text{ sonst.}\n\\end{array}\n\\right.\n$$\nDie zugehörige Verteilungsfunktion lautet\n$$\nF(x)=\\left\\{\n\\begin{array}{ll}\n0 & \\text{ für }x<0\\\\\n25/36 & \\text{ für }0\\le x<1\\\\\n35/36 & \\text{ für }1\\le x<2\\\\\n1 & \\text{ für }x\\ge 2.\n\\end{array}\n\\right.\n$$\nbzw. als Grafik\n```{r echo=FALSE}\nx <- c(0,1,2)\ny <- c(0,25/36,35/36,1)\nplot(stepfun(x,y),\n     verticals=FALSE, \n     pch=19,\n     xlab=\"x\",\n     ylab=\"F(x)\",\n     main=\"Verteilungsfunktion\")\n```\n:::\n\n## Stetige Zufallsvariablen\n\n::: callout-note\nEine Zufallsvariable $X$ heißt **stetig** (engl. continuous), wenn es eine\nFunktion $f_X(x)$ gibt, so dass\n$$\nF_X(x)=\\int_{-\\infty}^x f_X(t)dt\n$$\nfür alle $x\\in\\mathbb{R}$. Die Funktion $f_X(x)$ heißt **Dichtefunktion**\noder **Dichte** (engl. density function bzw. density). Wenn aus dem Kontext\nhervorgeht, zu welcher Zufallsvariable eine Dichte gehört, lässt man den\nSubindex gewöhnlich weg und schreibt einfach $f(x)$.\n:::\n\nDie Dichte hat folgende Eigenschaften:\n\n- Die Dichte kann nicht negativ sein, da sonst die Verteilungsfunktion\nnicht mehr monoton wachsend wäre. Es gilt also $f(x)\\le 0$ für alle $x\\in\\mathbb{R}$.\n\n- Die Fläche unter der Dichte muss 1 ergeben, da jede Verteiliungsfunktion $F_X(x)$\nfür $x\\to\\infty$ gegen 1 konvergiert. Es gilt also\n$$\n\\int_{-\\infty}^\\infty f(x)dx=1.\n$$\n\n- Die Dichte gibt an, wie steil die Verteilungsfunktion verläuft. Für\nalle Stellen, an denen die Verteilungsfunktion differenzierbar ist, gilt daher\n$$\nf(x)=F'(x).\n$$\nEs ist jedoch nicht unbedingt nötig, dass die Verteilungsfunktion überall\ndifferenzierbar ist, sie darf nicht differenzierbare Knicke enthalten.\nWenn es nicht differenzierbare Stellen in der Verteilungsfunktion gibt,\ndann weist die Dichte an diesen Stellen einen Sprung auf. \n\n- Der Wert der Dichte an einer Stelle $x$ ist *keine* Wahrscheinlichkeit.\nHingegen ist die Fläche unter der Dichte eine Wahrscheinlichkeit. So gilt\nbeispielsweise\n$$\nP(a<X\\le b)=\\int_a^b f(x)dx.\n$$\n\n- Die Wahrscheinlichkeit, dass eine stetige Zufallsvariable exakt den Wert\n$x$ annimmt, ist also (für jedes $x\\in\\mathbb{R}$)\n$$\nP(X=x)=0.\n$$\n\n- Die Menge $T_X=\\{x: f_X(x)>0\\}$ ist der Träger (engl. support)\nder Zufallsvariable $X$. Der Träger enthält alle Werte, die die\nZufallsvariable im Prinzip annehmen könnte.\n\nObwohl die Dichte selbst keine Wahrscheinlichkeit ist, hilft sie beim\nintuitiven Verständnis einer Verteilung trotzdem sehr. Man erkennt an \neinem Dichte-Plot sofort, in in welchen Bereichen die Zufallsvariable\nmit großer Wahrscheinlichkeit liegen wird und wo es eher unwahrscheinlich\nist.\n\n::: callout-tip\nDie Dichte der Zufallsvariable $X$ sei \n$$\nf(x)=\\left\\{\n\\begin{array}{ll}\n0 & \\text{ für }x < -0.56\\\\\nx^2-x^4+0.5 & \\text{ für }-0.56 \\le x < 1.1\\\\\n0 & \\text{ für }x \\ge 1.1.\n\\end{array}\n\\right.\n$$\nDer Plot der Dichte zeigt, dass die Realisation der Zufallsvariable $X$\nmit Sicherheit in dem Intervall\n$[-0.56, 1.1]$ liegen wird. Es ist eher unwahrscheinlich, dass ein Wert\nsehr nah an der rechten Grenzen realisiert wird. Auch der Bereich\num die 0 herum ist etwas weniger wahrscheinlich als die Bereiche\num die 0.75 herum oder nah an der linken Grenze.\n```{r echo=FALSE}\nx <- c(-1,-0.56,NA,seq(-0.56,1.1,length=100),NA,1.1,1.8)\nf <- 0.5-x^4+x^2\nf[c(1,2,105,106)] <- 0\nplot(x,f,t=\"l\",lwd=3,\n     xlab=\"x\",ylab=\"f(x)\",main=\"Dichte\")\n```\nDie Verteilungsfunktion erhält man durch Integration der Dichte.\n$$\nF(x)=\\left\\{\n\\begin{array}{ll}\n0 & \\text{ für }x < -0.56\\\\\n\\frac{1}{3}x^3-\\frac{1}{5}x^5+0.5x+0.3275 & \\text{ für }-0.56 \\le x < 1.1\\\\\n1 & \\text{ für }x \\ge 1.1.\n\\end{array}\n\\right.\n$$\nDie Konstante (0.3275) muss so gewählt werden, dass die Verteilungsfunktion\nam Punkt -0.56 bei 0 startet und am Punkt 1.1 bei 1 endet. Ein Plot der\nVerteilungsfunktion macht deutlich, dass die Verteilungsfunktion für\ndas schnelle Erfassen der Eigenschaften einer Verteilung nicht so gut\ngeeignet ist wie die Dichte. Die Realisation der Zufallsvariable liegt\nmit höherer Wahrscheinlichkeit in einem Bereich, in dem die Verteilungsfunktion\nsteil ist, als in einem Bereich, in dem sie flacher verläuft. Bereiche,\nin denen die Verteilungsfunktion gar nicht ansteigt, gehören nicht zum\nTräger der Zufallsvariable.\n```{r echo=FALSE}\nx <- c(-1,-0.56,seq(-0.56,1.1,length=100),1.1,1.8)\nf <- x^3/3-x^5/5+x/2+0.3275\nf[c(1,2)] <- 0\nf[c(103,104)] <- 1\nplot(x,f,t=\"l\",lwd=3,\n     xlab=\"x\",ylab=\"F(x)\",main=\"Verteilungsfunktion\")\n```\n:::\n\n## Quantilfunktion\n\nDie Quantilfunktion ist das Gegenstück zur Verteilungsfunktion. Während die\nVerteilungsfunktion auf die Frage antwortet \"Wie hoch ist die Wahrscheinlichkeit,\ndass die Zufallsvariable den Wert $x$ nicht übersteigt?\", beantwortet die\nQuantilfunktion die Frage \"Welcher Wert wird mit einer Wahrscheinlichkeit von \n$p$ nicht überschritten?\". Da es einige Fälle gibt, in denen diese Frage\nnicht eindeutig beantwortet werden kann, ist die formale Definition der\nQuantilfunktion etwas komplizierter:\n\n::: callout-note\nDie Funktion\n$$\nF_X^{-1}(p)=\\min\\{x:F_X(x)\\ge p\\}\n$$\nheißt **Quantilfunktion** von $X$. Der Wert $x_p=F_X^{-1}(p)$ \nheißt **p-Quantil** von $X$. Der Definitionsbereich ist $0<p<1$\n(also ohne die Intervallgrenzen).\n:::\n\nDen Subindex kann man weglassen, wenn sich die Zufallsvariable \naus dem Kontext ergibt. Gelegentlich findet man auch die \nalternative Notation $Q_X(p)$ oder $Q(p)$ für die Quantilfunktion.\nDas 0.5-Quantil heißt auch **Median** (engl. median).\n\nAus einer gegebenen Verteilungsfunktion lässt sich die Quantilfunktion\ndurch Invertieren finden. Das geht leicht, wenn die Verteilungsfunktion\nstreng monoton steigend verläuft. Aufpassen muss man jedoch, wenn\nsie Sprünge aufweist oder in einigen Bereichen flach verläuft.\n\n::: callout-tip\n- Zwei Würfel werden geworfen. Die Zufallsvariable $X$ sei die Anzahl\nder Sechsen. Die Verteilungsfunktion ist eine Treppenfunktion\nmit den Sprungstellen 0, 1 und 2, die hier noch einmal \ngezeigt wird. \n```{r echo=FALSE}\nx <- c(0,1,2)\ny <- c(0,25/36,35/36,1)\nplot(stepfun(x,y),\n     verticals=FALSE, \n     pch=19,\n     xlab=\"x\",\n     ylab=\"F(x)\",\n     main=\"Verteilungsfunktion\")\n```\nWie sieht die zugehörige Quantilfunktion aus? Um das zu beantworten,\nwandern wir langsam die y-Achse hoch und schauen jeweils, welches \nQuantil zu dem Wert gehört. Für Werte von $0<p\\le 25/36$ landet man\nauf dem Quantil 0. Für $25/36<p\\le 35/36$ ergibt sich das Quantil\n1 und für $p>35/36$ ist das Quantil 2. Also ist\n$$\nF^{-1}(p)=\\left\\{\n\\begin{array}{ll}\n0 & \\text{ für }0 < p \\le 25/36\\\\\n1 & \\text{ für }25/36 < p \\le 35/36\\\\\n2 & \\text{ für }p>35/36\n\\end{array}\n\\right.\n$$\nbzw. als Grafik\n```{r echo=FALSE}\np <- c(0,25/36,35/36,1)\nQ <- c(0,1,2)\nplot(p[1:2],Q[c(1,1)],\n     t=\"l\",\n     xlab=\"x\",\n     ylab=\"F(x)\",\n     xlim=c(0,1),\n     ylim=c(0,2),\n     main=\"Quantilfunktion\")\nfor(i in 2:length(Q)) lines(p[c(i,i+1)],Q[c(i,i)])\npoints(p[2:3],Q[1:2],pch=19)\n```\nIm Gegensatz zur Verteilungsfunktion ist die Quantilfunktion nicht\nrechtsstetig, sondern linksstetig. Der Funktionswert an einer Sprungstelle\nist gleich dem Grenzwert, wenn man sich von links der Sprungstelle nähert.\n:::\n\n\n## Erwartungswert\n\nDer Erwartungswert einer Verteilung gibt Auskunft darüber, wo der\n\"Schwerpunkt\" der Verteilung liegt. \n\n::: callout-note\nDer **Erwartungswert** (engl. expectation) einer Zufallsvariable ist\n$$\nE(X)=\\left\\{\n\\begin{array}{ll}\n\\sum\\limits_{j: x_j\\in T_X} x_j f(x_j) & \\text{ für X diskret}\\\\\n\\int\\limits_{-\\infty}^\\infty x f(x)dx & \\text{ für X stetig}\n\\end{array}\n\\right.\n$$\n:::\n\nWie der Erwartungswert einer Zufallsvariable berechnet wird, hängt also\ndavon ab, ob es sich um eine diskrete oder eine stetige Zufallsvariable\nhandelt. \n\n::: callout-tip\n- Zwei Würfel werden geworfen. Die Zufallsvariable $X$ sei die Anzahl\nder Sechsen. Wie hoch ist der Erwartungswert von $X$? Für die\nBerechnung benötigt man die Wahrscheinlichkeitsfunktion. Sie lautet\n(s. XXX)\n$$\nf(x)=\\left\\{\n\\begin{array}{ll}\n25/36 & \\text{ für }x=0\\\\\n10/36 & \\text{ für }x=1\\\\\n1/36 & \\text{ für }x=2\\\\\n0 & \\text{ sonst.}\n\\end{array}\n\\right.\n$$\nDer Erwartungswert ist \n$$\nE(X)=0\\cdot\\frac{25}{36}+1\\cdot\\frac{10}{36}+2\\cdot\\frac{1}{36}=\\frac{1}{3}.\n$$\n\n- Die Dichte der stetigen Zufallsvariable $X$ sei \n$$\nf(x)=\\left\\{\n\\begin{array}{ll}\n0 & \\text{ für }x < -0.56\\\\\nx^2-x^4+0.5 & \\text{ für }-0.56 \\le x < 1.1\\\\\n0 & \\text{ für }x \\ge 1.1.\n\\end{array}\n\\right.\n$$\nDer Erwartungswert dieser Zufallsvariable beträgt\n$$\n\\begin{align*}\nE(X) &= \\int_{-\\infty}^\\infty x f(x) dx\\\\\n&=\\int_{-0.56}^{1.1} x f(x) dx\\\\\n&=\\int_{-0.56}^{1.1} x (x^2-x^4+0.5) dx\\\\\n&=\\int_{-0.56}^{1.1} (x^3-x^5+0.5x) dx\\\\\n&=\\left. \\frac{1}{4}x^4-\\frac{1}{6}x^6+\\frac{1}{4}x^2 \\right|_{-0.56}^{1.1}\\\\\n&=0.3732-0.0978\\\\[1ex]\n&=0.2754.\n\\end{align*}\n$$\n:::\n\n## Varianz\n\nDie Varianz einer Zufallsvariable gibt an, wie stark die Verteilung \nstreut bzw. wie sehr man mit großen Abweichungen vom Erwartungswert\nrechnen sollte.\n\n::: callout-note\nDer **Varianz** (engl. variance) einer Zufallsvariable ist\n$$\nVar(X)=E\\left[(X-E(X))^2\\right].\n$$\nDie (positive) Wurzel aus der Varianz nennt man Standardabweichung\n(engl. standard deviation).\n:::\n\nFür diskrete und stetige Zufallsvariablen lässt sich die Varianz\nfolgendermaßen schreiben:\n$$\nVar(X)=\\left\\{\n\\begin{array}{ll}\n\\sum\\limits_{j:x_j\\in T_X} (x_j-E(X))^2 f(x_j) & \\text{ für X diskret}\\\\\n\\int\\limits_{-\\infty}^\\infty (x-E(X))^2 f(x)dx & \\text{ für X stetig}\n\\end{array}\n\\right.\n$$\n\nFür die Berechnung der Varianz ist manchmal der sogenannte\n**Streuungsverschiebungssatz** hilfreich:\n$$\nVar(X)=E(X^2)-(E(X))^2.\n$$\n\n::: callout-tip\n- Zwei Würfel werden geworfen. Die Zufallsvariable $X$ sei die Anzahl\nder Sechsen. Wie hoch ist die Varianz von $X$? Für die Berechnung nutzen\nwir den Streuungsverschiebungssatz. Der Erwartungswert von $X^2$ wird\nanalog zum Erwartungswert berechnet. Es ergibt sich\n$$\n\\begin{align*}\nE(X^2)&=\\sum_{j:x_j\\in T_X} x_j^2f(x_j)\\\\\n&=0^2\\cdot\\frac{25}{36}+1^2\\cdot\\frac{10}{36}+2^2\\cdot\\frac{1}{36}=\\frac{7}{18}.\n\\end{align*}\n$$\nDer Erwartungswert $E(X)$ wurde bereits im vorherigen Abschnitt berechnet,\nnämlich $E(X)=1/3$. Die Varianz ist folglich\n$$\n\\begin{align*}\nVar(X) &= E(X^2)-(E(X))^2\\\\\n&=\\frac{7}{18}-\\frac{1}{9}\\\\\n&= \\frac{5}{18}.\n\\end{align*}\n$$\n\n- Auch für die Berechnung der Varianz einer stetigen Zufallsvariable nutzen\nwir den Streuungsverschiebungssatz. Die Dichte der stetigen Zufallsvariable $X$ \nsei \n$$\nf(x)=\\left\\{\n\\begin{array}{ll}\n0 & \\text{ für }x < -0.56\\\\\nx^2-x^4+0.5 & \\text{ für }-0.56 \\le x < 1.1\\\\\n0 & \\text{ für }x \\ge 1.1.\n\\end{array}\n\\right.\n$$\nDer Erwartungswert von $X^2$ beträgt\n$$\n\\begin{align*}\nE(X^2) &= \\int_{-\\infty}^\\infty x^2f(x)dx\\\\\n&=\\int_{-0.56}^{1.1} x^2 (x^2-x^4+0.5)dx\\\\\n&=\\int_{-0.56}^{1.1} (x^4-x^6+0.5x^2)dx\\\\\n&=\\int_{-0.56}^{1.1} (x^4-x^6+0.5x^2)dx\\\\\n&=\\left. \\frac{1}{5}x^5-\\frac{1}{7}x^7+\\frac{1}{6}x^3 \\right|_{-0.56}^{1.1}\\\\\n&=0.2655-(-0.0378)\\\\[1ex]\n&=0.3033.\n\\end{align*}\n$$\nDer Erwartungswert von $X$ wurde bereits im letzten Abschnitt berechnet,\nund zwar $E(X)=0.2754$. Damit ergibt sich die Varianz als\n$$\n\\begin{align*}\nVar(X) &= E(X^2)-(E(X))^2\\\\\n&=0.3033-0.2754^2\\\\\n&= 0.2275.\n\\end{align*}\n$$\n:::\n\n## Lineare Transformationen\n\nEine lineare Transformation einer Zufallsvariable ergibt wieder eine\nZufallsvariable. Für zwei reelle Zahlen $a$ und $b$ ist\n$$\nY=aX+b\n$$\neine lineare Transformation von $X$. Welche Eigenschaften hat die\ntransformierte Zufallsvariable $Y$? Wir sehen uns an, wie sich die\nTransformation auf die Verteilungsfunktion, den Erwartungswert und die\nVarianz auswirkt.\n\nDie Verteilungsfunktion von $Y$ ist für $a>0$\n$$\n\\begin{align*}\nF_Y(y) &= P(Y\\le y)\\\\\n&= P(aX+b \\le y)\\\\\n&= P(aX \\le y-b)\\\\\n&= P\\left(X \\le \\frac{y-b}{a}\\right)\\\\\n&= F_X\\left(\\frac{y-b}{a}\\right).\n\\end{align*}\n$$\nFür $a<0$ dreht sich die Ungleichung bei der Division durch $a$ um, also gilt dann\n$$\n\\begin{align*}\nF_Y(y) &= P(Y\\le y)\\\\\n&= P(aX+b \\le y)\\\\\n&= P(aX \\le y-b)\\\\\n&= P\\left(X \\ge \\frac{y-b}{a}\\right)\\\\\n&= 1-P\\left(X <\\frac{y-b}{a}\\right).\n\\end{align*}\n$$\nWie die Beziehung des letzten Terms zur Verteilungsfunktion von $X$ aussieht,\nlässt sich nicht einfach allgemein beantworten. Wenn $X$ stetig verteilt ist,\nmacht es keinen Unterschied, ob in der Ungleichung ein \"$<$\" oder ein \"$\\le$\"\nsteht, dann ist also\n$$\nF_Y(y)=1-F_X\\left(\\frac{y-b}{a}\\right).\n$$\nWie wirkt sich eine lineare Transformation $Y=aX+b$ auf den Erwartungswert aus?\nWir untersuchen diskrete und stetige Zufallsvariablen getrennt voneinander.\nZuerst betrachten wir eine diskrete Zufallsvariable $X$ und $a,b\\in\\mathbb{R}$.\nDer Erwartungswert von $Y$ ist\n$$\n\\begin{align*}\nE(Y) &= E(aX+b)\\\\\n&= \\sum_{j\\in T_X}(ax_j+b)f(x_j)\\\\\n&= \\sum_{j\\in T_X}ax_j f(x_j) + \\sum_{j\\in T_X}b f(x_j)\\\\\n&= a\\sum_{j\\in T_X}x_j f(x_j) + b\\sum_{j\\in T_X}f(x_j)\\\\\n&= aE(X)+b,\n\\end{align*}\n$$\ndenn $\\sum_{j\\in T_X}f(x_j)=1$. Wenn $X$ eine stetige Zufallsvariable ist,\ndann gilt für den Erwartungswert der linearen Transformation\n$$\n\\begin{align*}\nE(Y) &= E(aX+b)\\\\\n&= \\int_{-\\infty}^\\infty (ax+b)f(x)dx\\\\\n&= \\int_{-\\infty}^\\infty ax f(x)dx + \\int_{-\\infty}^\\infty b f(x)dx\\\\\n&= a\\int_{-\\infty}^\\infty x f(x)dx + b\\int_{-\\infty}^\\infty f(x)dx\\\\\n&= aE(X)+b,\n\\end{align*}\n$$\nweil $\\int_{-\\infty}^\\infty f(x)dx=1$.\n\nEs gilt also sowohl für diskrete als auch für stetige Zufallsvariablen, \ndass der Erwartungswert der linearen Transformation der Zufallsvariable\nder linearen Transformation des Erwartungswerts entspricht. Kurz gesagt,\nkann man den Erwartungswert in eine lineare Funktion \"hineinziehen\"\noder ihn aus ihr \"herausziehen\". Man sagt auch, dass der Erwartungswert\nein \"linearer Operator\" ist.\n\n*Achtung*: Leider kann man der Erwartungswert im allgemeinen nicht aus anderen\n(nichtlinearen) Funktionen herausziehen oder ihn dort hineinziehen.\nSo ist beispielsweise im allgemeinen\n$$\nE(X^2) \\neq E(X)^2.\n$$\nDie Ergebnisse zum Erwartungswert können wir nun benutzen, um die\nVarianz einer linear transformierten Zufallsvariable zu untersuchen.\nEs gilt\n$$\n\\begin{align*}\nVar(Y) &= E((Y-E(Y))^2)\\\\\n&= E((aX+b-E(aX+b))^2)\\\\\n&= E((aX+b-(aE(X)+b))^2)\\\\\n&= E((aX+b-aE(X)-b)^2)\\\\\n&= E((aX-aE(X))^2)\\\\\n&= E(a^2(X-E(X))^2)\\\\\n&= a^2 E((X-E(X))^2)\\\\\n&= a^2 Var(X).\n\\end{align*}\n$$\nDiese Herleitung gilt sowohl für diskrete als auch für stetige Zufallsvariablen.\nOffensichtlich wirkt sich eine additive Verschiebung um $b$ überhaupt nicht\nauf die Varianz aus. Eine Multiplikation mit $a$ verändert die Varianz jedoch,\nund zwar um den Faktor $a^2$. Wenn $a>1$ ist, wird die Varianz also größer,\nwenn $0<a<1$ ist, wird sie kleiner. Beachten Sie, dass es für die Varianz\nkeine Rolle spielt, ob $a$ positiv oder negativ ist. Insbesondere bleibt die\nVarianz unverändert, wenn $X$ mit $(-1)$ multipliziert wird.\n\n## Standardisierung\n\nEine lineare Transformation, die dazu führt, dass der Erwartungswert der\ntransformierten Zufallsvariable 0 und die Varianz 1 ist, nennt man \n**Standardisierung**. Die transformierte Zufallsvariable heißt \nstandardisiert. Welche lineare Transformation muss für eine\nStandardisierung durchgeführt werden? Wie erreicht man, dass der \nErwartungswert nach der Transformation 0 ist und die Varianz 1?\n\nWir gehen in zwei Schritten vor. Im ersten Schritt subtrahieren wir von der\nZufallsvariablen $X$ ihren Erwartungswert $E(X)$ (also eine reelle Zahl),\n$$\nX-E(X).\n$$\nDie Zufallsvariable $X-E(X)$ hat den Erwartungswert\n$$\nE(X-E(X))=E(X)-E(X)=0.\n$$\nDie Varianz von $X-E(X)$ ist gleich der Varianz von $X$, denn die Varianz\nverändert sich nicht, wenn eine reelle Zahl addiert oder subtrahiert wird. \nDer Erwartungswert ist eine reelle Zahl. Man nennt die Zufallsvariable\n$X-E(X)$ auch **zentriert**.\n\nIm zweiten Schritt dividieren wir $X-E(X)$ durch die Standardabweichung von\n$X$,\n$$\n\\frac{X-E(X)}{\\sqrt{Var(X)}}.\n$$\nDadurch verändert sich der Erwartungswert nicht, er bleibt weiterhin 0. Wie\ngroß ist die Varianz? Um das zu beantworten, nutzen wir die Ergebisse zu\nVarianzen von linearen Transformationen, insb. das Ergebnis, dass eine multiplikative\nKonstante aus der Varianz herausgezogen werden kann, dann aber ins Quadrat\ngesetzt werden muss. Also ergibt sich\n$$\nVar\\left(\n\\frac{X-E(X)}{\\sqrt{Var(X)}}\n\\right)=\n\\frac{1}{Var(X)}Var(X-E(X))=1.\n$$\nFassen wir zusammen: Wenn $X$ eine Zufallsvariable mit Erwartungswert $E(X)$\nund Varianz $Var(X)$ ist, dann hat die linear transformierte Zufallsvariable\n$$\nY=\\frac{X-E(X)}{\\sqrt{Var(X)}}\n$$\nden Erwartungswert $E(Y)=0$ und die Varianz $Var(Y)=1$. In der Schreibweise\ndes vorhergehenden Abschnitts erreicht man eine Standardisierung von $X$ durch\ndie lineare Transformation $Y=aX+b$ mit $a=1/\\sqrt{Var(X)}$ und\n$b=E(X)/\\sqrt{Var(X)}$.\n\n"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["styles.css"],"output-file":"03-zufallsvariablen.html"},"language":{"toc-title-document":"Inhalt","toc-title-website":"In diesem Kapitel"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.2.475","bibliography":["references.bib"],"editor":"source","callout-icon":false,"callout-tip-title":"Beispiele","callout-note-title":"Definition","theme":"sandstone"},"extensions":{"book":{"multiFile":true}}}}}
>>>>>>> Stashed changes
