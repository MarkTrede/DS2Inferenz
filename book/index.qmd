# Einleitung {.unnumbered}

```{r echo=FALSE,warning=FALSE,out.width="99%"}
library(ggplot2)
knitr::include_graphics("images/AdobeStock_262173764b_DataScience.jpeg")
```

In den Wirtschaftswissenschaften spielen Zufall und Unsicherheit eine wichtige Rolle. Zum einen, weil die ökonomische Theorie deskriptive und normative Aussagen darüber macht, wie ökonomische Akteure sich unter Unsicherheit verhalten und wie sie sich rational verhalten sollten. Zum anderen, weil ökonomische Modelle mit Hilfe von statistischen Verfahren an die Realität angepasst werden sollen oder ökonomische Theorien anhand von emprischen Beobachtungen überprüft werden sollen. In dem Modul **Data Science 2** lernen Sie, wie man mit Zufall und Unsicherheit umgeht.

Das Modul lässt sich in zwei große Teile gliedern, nämlich die Grundlagen der Wahrscheinlichkeitstheorie und die statistische Inferenz. 

## Wahrscheinlichkeitstheorie {.unnumbered}

Warum braucht man in den Wirtschaftswissenschaften Wahrscheinlichkeitstheorie? Es gibt zwei Gründe:
Zum einen taucht die Wahrscheinlichkeitstheorie in der ökonomischen Theorie auf, wenn es 
um das Verhalten von ökonomischen Agenten unter Unsicherheit geht. 
Die Wahrscheinlichkeitstheorie ist also hier weniger ein Zweig der Mathematik, 
sondern dient zur Beschreibung des Verhaltens von Menschen unter Unsicherheit. 
In @sec-zufall wird ein formaler Rahmen eingeführt, in dem man 
präzise mit Unsicherheit umgehen kann. Unsicherheit bedeutet, dass man nicht 
genau und sicher weiß, was passieren wird. Praktisch befinden wir uns also in der 
Realität so gut wie immer in einer Situation unter Unsicherheit. In @sec-wahrscheinlichkeit
lernen Sie, was man unter Wahrscheinlichkeit versteht. Aufbauend auf den
ersten beiden Kapiteln wird anschließend in @sec-zufallsvariablen definiert,
was Zufallsvariablen sind. Mit ihnen lassen sich in vielen Situationen 
Zufallsvorgänge sehr einfach erfassen. In @sec-verteilungen lernen Sie eine
Reihe von Standardverteilungen kennen. Bei vielen wissenschaftlichen Fragen
geht es darum, wie mehrere Größen miteinander zusammenhängen. Auch dafür
braucht man einen sauberen formalen Rahmen. Er wird in @sec-zufallsvektoren
und @sec-kovarianz vorgestellt. 

Wahrscheinlichkeitstheorie ist noch aus einem zweiten, technischen Grund
wichtig in der Ökonomik: Die Wahrscheinlichkeitstheorie bildet das formale Fundament 
für die statistische Inferenz, also die Kunst, Rückschlüsse von einer Stichprobe auf
die Population zu ziehen. Der Übergang zur statistischen Inferenz wird
in @sec-grenzwerte vorbereitet. Dort lernen Sie das Gesetz der großen Zahl und 
den zentralen Grenzwertsatz kennen.

## Statistische Inferenz {.unnumbered}

Bei der statistischen Inferenz schließt man von einer Stichprobe
auf die Population. Man spricht daher auch von "schließender Statistik".
Es geht letztlich um die Frage "Was können uns die Daten 
eigentlich sagen?" Sind die Ergebnisse, die wir ausrechnen, wirklich
zuverlässig? Wie groß ist die mögliche Fehlerspanne unserer Resultate? 
Wie können wir Theorien oder Hypothesen empirisch überprüfen, wenn uns
keine perfekten Daten vorliegen? In @sec-stichproben lernen Sie, was 
man in der Wissenschaft unter einer Stichprobe versteht. In den
nachfolgenden Kapiteln wird dann gezeigt, wie man Stichproben nutzen kann.
In @sec-punktschaetzung und @sec-intervallschaetzung geht es um
Punktschätzungen und Konfidenzintervalle. In @sec-hypothesentests wird 
ausführlich erklärt, was statistische Hypothesentests sind, welche
"Philosophie" ihnen zugrunde liegt und wie man sie durchführt.
In @sec-erwwerttests wird gezeigt, wie man Hypothesen 
über Erwartungswerte testet, in @sec-weiteretests geht es um
weitere Arten von Hypothesentests. Am Ende des Semesters wird
in @sec-bootstrap ein sehr allgemeiner computer-gestützter 
Testansatz vorgestellt, die sogenannte Bootstrap-Methode.

In diesem Kurs bauen alle späteren Kapitel auf früheren Kapiteln
auf. Die statistische Inferenz in Form von Hypothesentests,
Konfidenzintervallen und Punktschätzungen (@sec-punktschaetzung
bis @sec-bootstrap) ist nur dann wirklich verständlich, wenn man 
vorher das Konzept einer Stichprobe (@sec-stichproben) verinnerlicht 
hat und die beiden grundlegenden Arten von Grenzwertsätzen kennt
(@sec-grenzwerte). Dafür ist eine Voraussetzung der Umgang
mit gemeinsamen Verteilungen (@sec-zufallsvektoren und @sec-kovarianz). 
Zuvor muss man jedoch wissen, wie man mit univariaten Zufallsvariablen 
umgeht (@sec-zufallsvariablen und @sec-verteilungen). Um zu verstehen, was
eine Zufallsvariable eigentlich ist, braucht man grundlegende Kenntnisse
der Wahrscheinlichkeitstheorie (@sec-zufall und @sec-wahrscheinlichkeit).
<hr>

Der Name dieses Moduls "Data Science 2" lässt vermuten, dass dieses 
Modul auf dem Modul "Data Science 1" aufbaut. Diese Vermutung ist aber 
falsch. Beide Module sind inhaltlich in sich abgeschlossen und 
können unabhängig voneinander belegt werden. Wenn Sie "Data Science 1" 
bereits gehört haben, werden Sie jedoch feststellen, dass viele 
Begriffe, die Sie dort gelernt haben, in ähnlicher Form auch 
in "Data Science 2" vorkommen. Das ist kein Zufall, denn wir werden
sehen, dass auf einer tieferen Ebene eine enge Beziehung zwischen 
beiden Ansätzen besteht. Anders als "Data Science 1" ist der Inhalt des 
Mathematik-Moduls "Analysis für Wirtschaftswissenschaften" jedoch eine 
wichtige Voraussetzung in diesem Kurs. Wenn Sie Lücken 
bei den Themen Differential- und Integrationsrechnung befürchten, sollten 
Sie auf jeden Fall die Inhalte des Analysis-Moduls wiederholen.

Vorausgesetzt wird ferner, dass Sie R und RStudio nutzen können.
Die Software R wird in diesem Modul zwar nicht gleich zu Beginn
des Semesters eingesetzt, aber sie spielt eine sehr wichtige Rolle,
weil R das Verständnis von Zufall enorm erleichtern kann und
weil einige der vorgestellten Methoden ausschließlich mit
Hilfe eines Computers durchführbar sind. Im @sec-programmieren finden 
Sie einige Hinweise zum Programmieren in R, insbesondere zu Vektoren 
und Schleifen. 

Hinweise auf weiterführende Literatur 
gibt @sec-literatur. Dieses eLehrbuch orientiert sich sowohl hinsichtlich 
seines Aufbaus als auch der Notation recht eng an Mosler und Schmid (2011).
Zum Layout in diesem eLehrbuch: Die (meisten) Definitionen sind blau unterlegt. 
Beispiele sind grün unterlegt und meistens mit einem Mausklick aus- und wieder 
einklappbar. Es gibt nur wenige Theoreme, sie sind rot unterlegt. Die 
Grafiken wurden alle in R erstellt. Der zugehörige R-Code ist für diesen Kurs
nicht relevant, wer sich dennoch dafür interessiert, kann über den Grafiken
auf "R-Code zeigen" klicken.

<a rel="license" href="http://creativecommons.org/licenses/by-nc-nd/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-nd/4.0/88x31.png" /></a><br />Dieses Lehrbuch unterliegt der <a rel="license" href="http://creativecommons.org/licenses/by-nc-nd/4.0/">Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License</a>.

