# Zufallsvektoren {#zufallsvektoren}

Zufallsvariablen sind Funktionen aus dem Ergebnisraum in die Menge der
reellen Zahlen. Es ist natürlich möglich, nicht nur eine solche Funktion 
zu betrachten, sondern mehrere gleichzeitig. Man erhält dann mehrere
Zufallsvariablen, die jedoch alle vom gleichen zugrundeliegenden 
Zufallsvorgang abhängen und auf dem gleichen Ergebnisraum $\Omega$
basieren. Ordnet man diese Zufallsvariablen in Form eines
Vektors an, dann spricht man von einem **Zufallsvektor** 
(engl. random vector). Man sagt
auch, dass die Zufallsvariablen eine **gemeinsame Verteilung** 
(engl. joint distribution) haben.

Gemeinsame Verteilungen sind erheblich interessanter und vielseitiger
als eindimensionale Zufallsvariablen, weil sie auch Zusammenhänge
und Abhängigkeiten zwischen den Variablen beschreiben können.

::: callout-tip
- Zwei Würfel werden geworfen. Die Zufallsvariable $X$ sei die
kleinere Augenzahl, die Zufallsvariable $Y$ die größere Augenzahl.
Die beiden Zufallsvariablen $X$ und $Y$ basieren auf dem gleichen
Ergebnisraum. Sie haben eine gemeinsame Verteilung. Das lässt
sich etwa so veranschaulichen:
$$
\begin{array}{lclcl}
\mathbb{R}& X & \Omega & Y & \mathbb{R}\\\hline
1 & \longleftarrow & 11 & \longrightarrow & 1\\
1 & \longleftarrow & 12 & \longrightarrow & 2\\
1 & \longleftarrow & 13 & \longrightarrow & 3\\
1 & \longleftarrow & 14 & \longrightarrow & 4\\
1 & \longleftarrow & 15 & \longrightarrow & 5\\
1 & \longleftarrow & 16 & \longrightarrow & 6\\
1 & \longleftarrow & 21 & \longrightarrow & 2\\
2 & \longleftarrow & 22 & \longrightarrow & 2\\
2 & \longleftarrow & 23 & \longrightarrow & 3\\
\vdots && \vdots&&\vdots\\
5 & \longleftarrow & 65 & \longrightarrow & 6\\
6 & \longleftarrow & 66 & \longrightarrow & 6
\end{array}
$$

- Wir betrachten die Tagesrenditen von zwei Aktien an einem zukünftigen Tag. 
Sei $X$ die Tagesrendite der Volkswagenaktie und $Y$ die Tagesrendite von
BASF. Dann haben $X$ und $Y$ eine gemeinsame Verteilung.
:::

Im folgenden gehen wir Schritt für Schritt fast genauso vor wie bei den 
univariaten Zufallsvariablen in Kapitel XXX.

## Verteilungsfunktion

Alle wichtigen Eigenschaften der Verteilung einer univariaten 
Zufallsvariable werden durch ihre Verteilungsfunktion beschrieben. 
Wie lässt sich die Idee einer Verteilungsfunktion auf 
Zufallsvektoren übertragen? 

::: callout-note
Sei $\Omega$ eine Ergebnismenge, seien $X:\Omega \longrightarrow \mathbb{R}$ 
und $Y:\Omega\longrightarrow \mathbb{R}$ zwei Zufallsvariablen. Dann ist
\[ F_{XY}(x,y) =P(X\leq x,Y\leq y) \]
die **gemeinsame Verteilungsfunktion** (engl. joint cumulative
distribution function) von $X$ und $Y$.
:::

Wenn aus dem Kontext eindeutig hervorgeht, um welchen Zufallsvektor
bzw. um welche Zufallsvariablen es sich handelt, kann der Subindex entfallen.
Die gemeinsame Verteilungsfunktion lässt sich leicht auf mehr als zwei
Zufallsvariablen verallgemeinern. Da die Notation dann etwas unübersichtlicher
wird, beschränken wir uns auf den Fall von zwei Zufallsvariablen. Alle
wichtigen Konzepte lassen sich auch gut in diesem Fall verstehen.

Eigenschaften der gemeinsamen Verteilungsfunktion:

- $F_{XY}(x,y)=P(X\leq x,Y\leq y)$ ist monoton steigend 
(aber nicht unbedingt streng monoton steigend) in $x$ und $y$.

- Es gilt $\lim_{x\to -\infty}F_{XY}(x,y)$ und $\lim_{y\to -\infty}F_{XY}(x,y)=0$.

- Es gilt $\lim_{z\to \infty}F_{XY}(z,z) =1$.

## Gemeinsam diskrete Zufallsvariablen

Im univariaten Fall haben wir uns auf zwei Klassen von Zufallsvariablen
beschränkt, nämlich diskrete und stetige Zufallsvariablen. Das 
lässt sich leicht auf den mehrdimensionalen Fall verallgemeinern. 

::: callout-note
Zwei Zufallsvariablen $X$ und $Y$ heißen **gemeinsam diskret**
(jointly discrete),  wenn es endlich viele oder 
abzählbar unendlich viele Werte 
$x_1,x_2,\ldots$ und $y_1,y_2,\ldots $ gibt, so dass 
$$
\sum_{j}\sum_{k}p_{jk}=1
$$
mit $p_{jk}=P(X=x_j,Y=y_k)$.
:::

Gemeinsam diskrete Zufallsvariablen haben eine 
**gemeinsame Wahrscheinlichkeitsfunktion**
(engl. joint probability function), nämlich
$$
f_{XY}(x,y) =\left\{ 
\begin{array}{ll}
p_{jk} & \quad \text{für }x=x_{j}\text{ und }y=y_{k} \\ 
0 & \quad \text{sonst.}
\end{array}\right.
$$
Wenn die Zahl der unterschiedlichen möglichen Werte, die $X$ und $Y$
annehmen können, nicht allzu groß ist, dann kann man die 
gemeinsamen Wahrscheinlichkeiten übersichtlich in Form einer
Wahrscheinlichkeitstabelle darstellen:
$$
\begin{array}{c|ccc}
X\backslash Y & y_{1} & \ldots & y_{K} \\ \hline
x_{1} & p_{11} & \ldots  & p_{1K} \\ 
\vdots& \vdots &  & \vdots  \\ 
x_{J} & p_{J1} & \ldots  & p_{JK}
\end{array}
$$

::: callout-tip
Zwei Würfel werden geworfen. Die gemeinsame Wahrscheinlichkeitsfunktion 
der beiden Zufallsvariablen $X$: "kleinere Augenzahl" und 
$Y$: "größere Augenzahl" sieht als Wahrscheinlichkeitstabelle so aus:
$$
\begin{array}{c|cccccc}
X\backslash Y & 1 & 2 & 3 & 4 & 5 & 6 \\ \hline
1 & \frac{1}{36} & \frac{2}{36} & \frac{2}{36} & \frac{2}{36} & \frac{2}{36} & \frac{2}{36} \\
2 & 0            & \frac{1}{36} & \frac{2}{36} & \frac{2}{36} & \frac{2}{36} & \frac{2}{36} \\
3 & 0            & 0            & \frac{1}{36} & \frac{2}{36} & \frac{2}{36} & \frac{2}{36} \\
4 & 0            & 0            & 0            & \frac{1}{36} & \frac{2}{36} & \frac{2}{36} \\
5 & 0            & 0            & 0            & 0            & \frac{1}{36} & \frac{2}{36} \\
6 & 0            & 0            & 0            & 0            & 0            & \frac{1}{36}
\end{array}
$$
Der Wert der gemeinsamen Verteilungsfunktion an der Stelle
$(x,y)=(5.3, 2)$ gibt die Wahrscheinlichkeit an, dass $X\le 5$ ist
und gleichzeitig $Y\le 2$. Diese Wahrscheinlichkeit ergibt sich,
indem man alle Wahrscheinlichkeiten aus der Tabelle addiert,
die in den ersten beiden Spalten ($Y\le 2$) und in den
ersten fünf Zeilen ($X\le 5.3$) stehen. Man erhält
$$
F_{XY}(5.3,2)=\frac{1}{36}+\frac{2}{36}+\frac{1}{36}=\frac{4}{36}=\frac{1}{9}.
$$
:::

## Gemeinsam stetige Zufallsvariablen

::: callout-note
Die Zufallsvariablen $X$ und $Y$ heißen **gemeinsam stetig**
(engl. jointly continuous), falls es eine Funktion $f_{XY} $ gibt mit 
$$
F_{XY}(x,y)=\int_{-\infty }^{y}\int_{-\infty }^{x}f_{XY}(u,v)dudv.
$$
Die Funktion $f_{XY}$ heißt **gemeinsame Dichte** oder Dichtefunktion
(engl. joint density function) von $X$ und $Y$.
:::

Wenn die Verteilungsfunktion partiell differenzierbar ist, dann
erhält man die Dichte, indem man die Verteilungsfunktion nach beiden
Argumenten ableitet,
$$
f_{XY}(x,y)=\frac{\partial^2}{\partial x\partial y}F_{XY}(x,y).
$$
Da die Verteilungsfunktion monoton steigend ist, kann die Dichte
nie negativ sein (sie kann jedoch in einigen Bereichen 0 sein). Für
$x,y\in\mathbb{R}$ gilt also
$$
f_{XY}(x,y)\ge 0.
$$
Das gesamte Volumen unter der Dichte beträgt 1,
$$
\int_{-\infty }^{\infty }\int_{-\infty }^{\infty }f_{XY}(x,y)dxdy=1.
$$
Die gemeinsame Dichte zweier Zufallsvariablen kann man sich als
Gebirge mit einem Volumen von 1 vorstellen. Die Bereiche $(x,y)$, 
in denen das Gebirge hoch ist, kommen mit einer höheren 
Wahrscheinlichkeit vor, als die Bereiche, in denen es niedrig ist.

::: callout-tip
Die gemeinsame Dichte der beiden Zufallsvariablen $X$ und $Y$ sei
für $x,y\in\mathbb{R}$
$$
f(x,y)=\frac{2e^{-x-y}}{(1+e^{-x}+e^{-y})^3}.
$$
In der folgenden 3D-Abbildung, die Sie mit der Maus bewegen können
(allerdings leider nicht auf einem Tablet), erkennt man, dass die
Dichte um den Punkt $(0,0)$ herum besonders hoch ist. Die 
gemeinsame Realisation von $X$ und $Y$ wird also mit hoher
Wahrscheinlichkeit irgendwo in der Nähe des Nullpunkts liegen. 
Außerdem ist eine leichte Asymmetrie zu erkennen. Es ist sehr
unwahrscheinlich, dass sowohl $X$ als auch in $Y$ beide größer als
3 sind. Hingegen kann es (wenn auch mit eher kleiner Wahrscheinlichkeit)
passieren, dass beide Zufallsvariable kleiner als $-3$ sind.
```{r echo=FALSE}
library(rgl)
x <- y <- seq(-4,4,length=101)
f <- matrix(0,length(x),length(y))
for(i in 1:length(x)){
    for(j in 1:length(y)){
        f[i,j] <- (2*exp(-x[i])*exp(-y[j]))/(1+exp(-x[i])+exp(-y[j]))^3
    }
}
persp3d(x,y,f,col="light green",
        xlab="x",ylab="y",zlab="f(x,y)")
rglwidget()
close3d()
```

Weitere Möglichkeiten, ein Dichte"gebirge" grafisch darzustellen,
sind Contour-Plots und Image-Plots. In einem Contour-Plot sieht man die Höhenlinien 
der Dichtefunktion wie auf einer normalen Landkarte. In einem Image-Plot 
werden die Höhen durch Farben repräsentiert. 

Der Contour-Plot für die obige Dichte sieht so aus:
```{r echo=FALSE, fig.asp=1}
contour(x,y,f,
        xlab="x",ylab="y")
```
Ein Vorteil des Contour-Plots besteht darin, dass man leicht erkennen kann,
wo die Dichte hoch ist. Ein farbiger Image-Plot der gleichen Dichte zeigt folgendes Bild:
```{r fig.asp=1, echo=FALSE}
filled.contour(x,y,f,
               xlab="x",ylab="y")
```
:::

Wenn man sich für die Wahrscheinlichkeit interessiert, dass die
Zufallsvariable in einem bestimmten Bereich landet, muss man
das Volumen der Dichte über diesem Bereich berechnen. Für
einen rechteckigen Bereich $[a_1,b_1]\times [a_2,b_2]$
berechnet man das Doppel-Integral
$$
P(a_1< X \le b_1, a_2 < X\le b_2)=\int_{a_2}^{b_2}\int_{a_1}^{b_1}
f(x,y)dxdy.
$$
Lässt man das Rechteck unendlich groß werden, ergibt sich das
Gesamtvolumen 1. Die Herleitung des Doppelintegrals ist in vielen
Fällen umständlich, in manchen Fällen sogar in geschlossener Form
unmöglich. Numerische Approximationsverfahren (die wir in diesem
Kurs aber nicht behandeln) erlauben jedoch so gut wie immer eine
sehr genaue Berechnung der Wahrscheinlichkeit. In dem folgenden
Beispiel ist die Dichte des Zufallsvektors von einer Form, die
eine geschlossene Herleitung des Doppelintegrals erlaubt.

::: callout-tip
Der gemeinsam stetig verteilte Zufallsvektor $(X,Y)$ hat die
gemeinsame Dichtefunktion
$$
f(x,y)=\left\{
\begin{array}{ll}
x+y^2 & \text{ für }0\le x \le 1.11963\text{ und }0\le y\le 1\\
0 & \text{ sonst.}
\end{array}
\right.
$$
Wie groß ist die Wahrscheinlichkeit, dass $X$ in dem Intervall $[0.5,0.75]$
und gleichzeitig $Y$ in dem Intervall $[0.2,0.5]$ liegt? Diese
Wahrscheinlichkeit ergibt sich als das Doppelintegral
$$
P(0.5< X\le 0.75,0.2<Y\le 0.5)=
\int_{0.2}^{0.5}\int_{0.5}^{0.75}(x+y^2)dxdy.
$$
Zuerst bestimmen wir das innere Integral. Es ist
$$
\int_{0.5}^{0.75}(x+y^2)dx=\left.\frac{1}{2}x^2+xy^2\right|_{0.5}^{0.75}=0.25y^2+0.15625.
$$
Dieser Ausdruck wird nun in das äußere Integral eingesetzt. Man
erhält
$$
\int_{0.2}^{0.5}(0.25y^2+0.15625)dy=
\left. \frac{1}{12}y^3+0.15625y\right|_{0.2}^{0.5}=
0.056625.
$$
Die Wahrscheinlichkeit, das die Realisation des Zufallsvektors in dem 
Rechteck $[0.5,0.75]\times[0.2,0.5]$ liegt, beträgt also 5.7 Prozent.
:::

## Randverteilungen

Alle Informationen über die gemeinsame Verteilung eines Zufallsvektors $(X,Y)$
sind in der gemeinsamen Dichte oder der gemeinsamen Verteilungsfunktion
enthalten. In manchen Situationen interessiert man sich jedoch gar nicht
für die gemeinsame Verteilung, sondern nur für die Verteilung einer
der beiden Variablen. 

::: callout-note
Als **Randverteilung** bezeichnet man die Verteilung einer
Zufallsvariablen eines Zufallsvektors, wenn die restlichen
Zufallsvariablen des Zufallsvektors ignoriert werden.
:::

Die Randverteilungen lassen sich besonders einfach aus der gemeinsamen
Verteilungsfunktion $F_{XY}(x,y)$ ableiten. Es gilt nämlich
$$
\begin{align*}
F_X(x)&=F_{XY}(x,\infty)=\lim_{y\to\infty}F_{XY}(x,y)\\
F_Y(y)&=F_{XY}(\infty,y)=\lim_{x\to\infty}F_{XY}(x,y),
\end{align*}
$$
wobei $F_X$ und $F_Y$ die Randverteilungsfunktionen von $X$ und $Y$
sind. Man erhält also die Randverteilungsfunktionen, indem man die
jeweils andere Variable gegen unendlich gehen lässt. 

Wenn $X$ und $Y$ gemeinsam diskret verteilt sind, ergeben sich die
Randwahrscheinlichkeitsfunktionen aus der gemeinsamen
Wahrscheinlichkeitsfunktion,
$$
\begin{align*}
p_{j\cdot}&=P(X=x_j)=\sum_k p_{jk}\\
p_{\cdot k}&=P(Y=y_k)=\sum_j p_{jk}.
\end{align*}
$$
Wenn $X$ und $Y$ gemeinsam stetig verteilt sind, erhält man
die Randdichten aus der gemeinsamen Dichte wie folgt.
$$
\begin{align*}
f_X(x)&=\int_{-\infty}^\infty f_{XY}(x,y)dy\\
f_Y(y)&=\int_{-\infty}^\infty f_{XY}(x,y)dx.
\end{align*}
$$

## Unabhängigkeit

::: callout-note
Zwei Zufallsvariablen $X$ und $Y$ heißen **stochastisch unabhängig**
oder **unabhängig**, wenn für alle $x,y\in\mathbb{R}$ gilt
$$
F_{XY}(x,y)=F_X(x)\cdot F_Y(y).
$$
:::

Wenn die Zufallsvariablen nicht unabhängig sind, nennt man sie abhängig.
Sowohl bei abhängigen als auch bei unabhängigen Zufallsvariablen gilt,
dass die Randverteilungen aus der gemeinsamen Verteilung hergeleitet
werden können. Im Gegensatz dazu ist die Herleitung der gemeinsamen
Verteilung aus den Randverteilungen nur möglich, wenn die Zufallsvariablen
unabhängig sind.

Wenn $X$ und $Y$ gemeinsam diskret verteilt sind, dann gilt bei
Unabhängigkeit für alle $j$ und $k$
$$
p_{jk}=p_{j\cdot}\cdot p_{\cdot k}.
$$
Wenn $X$ und $Y$ gemeinsam stetig verteilt sind, ergibt sich bei
Unabhängigkeit die gemeinsame Dichte als Produkt der beiden
Randdichten,
$$
f_{XY}(x,y)=f_X(x)\cdot f_Y(y).
$$





## Bedingte Verteilungen

## Kovarianz

## Linearkombinationen
