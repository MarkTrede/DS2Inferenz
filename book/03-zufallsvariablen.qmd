# Zufallsvariablen {#zufallsvariablen}

Die wichtigsten formalen Grundlagen der Wahrscheinlichkeitstheorie sind nun gelegt. Darauf aufbauend definieren wir Zufallsvariablen. Zufallsvariablen sind - intuitiv gesprochen - Zahlen, deren Wert man noch nicht kennt, deren Wert sich aber (irgendwann) realisiert. Die formale Definition von Zufallsvariablen bezieht sich auf die Ergebnismenge.

::: callout-note
Eine Abbildung 
$$
X: \Omega\rightarrow \mathbb{R}
$$ 
heißt **Zufallsvariable** (engl. random variable).
:::

Eine Zufallsvariable kann man sich zwar als eine Zahl vorstellen, deren Wert man noch nicht kennt. Formal gesehen handelt es sich jedoch um eine Funktion, die jedem Element der Ergebnismenge genau eine reelle Zahl zuordnet.

::: callout-tip
Als Beispiel betrachten wir ein Zufallsexperiment, bei dem zwei Würfel geworfen
werden. Jeder der beiden Würfel zeigt dann 1, 2, 3, 4, 5 oder 6.
Der Ergebnisraum hat folglich 36 Elemente, nämlich
$$
\Omega=\{11,12,13,14,15,16,21,22,23,\ldots,65,66\}.
$$
Nun definieren wir eine Zufallsvariable $X$, die angibt, wie hoch die
Summe der Augenzahlen ist. Offensichtlich kann es passieren, dass beide
Würfel 1 zeigen, dann ist $X=2$. Wenn einer der Würfel eine 1 anzeigt,
der andere eine 2, dann ist $X=3$ usw. Die Abbildung bzw. Funktion aus dem 
Ergebnisraum in die Menge der reellen Zahlen sieht also so aus:
$$
\begin{array}{lll}
\Omega && \mathbb{R}\\\hline
11 & \longrightarrow & 2\\
12 & \longrightarrow & 3\\
13 & \longrightarrow & 4\\
14 & \longrightarrow & 5\\
15 & \longrightarrow & 6\\
16 & \longrightarrow & 7\\
21 & \longrightarrow & 3\\
22 & \longrightarrow & 4\\
23 & \longrightarrow & 5\\
\vdots&&\vdots\\
65 & \longrightarrow & 11\\
66 & \longrightarrow & 12
\end{array}
$$
:::

Wenn die Zufallsvariable sich realisiert, bezeichnet man die **Realisation** gewöhnlich mit einem Kleinbuchstaben. Beispielsweise ist $x$ die Realisation der Zufallsvariable $X$. Gedanklich ist es oft hilfreich, sich $X$ (also die Zufallsvariable) als die Situation ex ante und $x$ (also die Realisierung) als die Situation ex post vorzustellen.

Beachten Sie den großen Unterschied zwischen einer Zufallsvariable und ihrer Realisation. Die Zufallsvariable ist eine Funktion, die Realisation ist eine reelle Zahl. Wahrscheinlichkeitsaussagen lassen sich nur über Zufallsvariablen treffen, nicht über ihre Realisation.

::: callout-tip
Wir betrachten weiterhin das Zufallsexperiment mit zwei Würfeln. 
Wie hoch ist die Wahrscheinlichkeit, dass die Zufallsvariable $X$: "Summe
der beiden Augenzahlen" den Wert 4 annimmt? Um diese eigentlich sehr einfache
Frage in dem formalen Rahmen sauber zu beantworten, müssen wir zunächst 
ermitteln, welche Ergebnisse aus $\Omega$ dazu führen, dass $X=4$ ist (das
sogenannte Urbild von $X=4$).

Es gibt drei Ergebnisse, die auf $X=4$ führen, nämlich $13,22$ und $31$. 
Nun fragen wir uns, wie wahrscheinlich das Ereignis $\{13,22,31\}$ ist? Die
Antwort ist einfach, weil es sich um ein Laplace-Experiment handelt,
$$
P(X=4)=P(\{13,22,31\})=\frac{|(\{13,22,31\}|}{|\Omega|}=\frac{3}{36}=\frac{1}{12}.
$$
:::

Um mit Zufallsvorgängen in der Ökonomik zu arbeiten, sind Zufallsvariablen eine 
große Hilfe. Praktisch alle Vorgänge, bei denen der Zufall oder Unwissenheit 
eine Rolle spielen, lassen sich gut mit Hilfe von Zufallsvariablen beschreiben. 
In fast allen Fällen wird die Funktion
$X:\Omega\to\mathbb{R}$ nicht explizit angegeben, sondern implizit als
vorhanden vorausgesetzt. Trotzdem ist es wichtig zu erkennen, dass 
Zufallsvariablen quasi auf dem mengentheoretischen Fundament aufbauen, dass
wir in den vorangegangenen Kapiteln gelegt haben.

::: callout-tip
Mögliche Zufallsvariablen in der Ökonomik:

- Die Zufallsvariable $X$ steht für den Gewinn einer Aktiengesellschaft im kommenden Jahr. Wenn das Jahr vergangen ist, hat sich der Gewinn $x$ realisiert. Von den ex ante vielen möglichen
Gewinnen hat sich nur einer tatsächlich eingestellt.

- $X$ bezeichnet den Erwerbsstatus einer zufällig aus einer Population ausgewählten Person (0=nicht erwerbstätig, 1=Teilzeit, 2=Vollzeit). Sobald eine Person tatsächlich ausgewählt und befragt wurde, hat sich die Zufallsvariable realisiert und es ist dann entweder $x=0$ oder $x=1$
oder $x=2$..

- $X$ ist das Nettomonatseinkommen eines zufällig ausgewählten Haushalts einer Population. Nachdem ein Haushalt zufällig ausgewählt und befragt wurde, hat sich die Zufallsvariable realisiert und ist zum Beispiel $x=3456$.

- $X$ ist die Dauer, die ein technisches Gerät ohne Fehler funktioniert. Am
Start des Geräts weiß man noch nicht, wie lange es fehlerfrei laufen wird.
Sobald ein Fehler auftritt, hat sich die Zufallsvariable realisiert. Die
Realisation ist dann beispielsweise $x=12345$ Stunden.
:::

## Verteilungsfunktion

Wir wissen zwar nicht, welchen Wert eine Zufallsvariable annehmen wird, aber oft wissen wir, dass bestimmte Werte mit einer höheren Wahrscheinlichkeit vorkommen als andere Werte. So wissen wir zum Beispiel, dass beim Werfen mit zwei Würfeln die Augensumme 2 weniger wahrscheinlich ist als die Augensumme 7, denn für die Augensumme 2 müssen beide Würfel eine 1 zeigen, für die Augensumme 7 gibt es dagegen viel mehr Möglichkeiten (nämlich 16, 25, 34, 43, 52 und 61). Um die Verteilung einer Zufallsvariable zu beschreiben, gibt es mehrere Möglichkeiten. Eine besonders wichtige ist die Verteilungsfunktion.

::: callout-note
Die **Verteilungsfunktion** (engl. cumulative distributio function, cdf) einer Zufallsvariable $X$ gibt für $x\in\mathbb{R}$ die Wahrscheinlichkeit an, dass $X\le x$ ist,
$$
F_X(x)=P(\{\omega: X(\omega)\le x\})
$$
oder in Kursschreibweise
$$
F_X(x)=P(X\le x).
$$
Wenn die Zufallsvariable sich aus dem Kontext erschließt, schreibt man auch
anstelle von $F_X(x)$ einfach $F(x)$.
:::

Die Verteilungsfunktion einer Zufallsvariable ist sehr nützlich, weil durch sie die
Verteilung der Zufallsvariable eindeutig charakterisiert wird. Kennt man die Verteiliungsfunktion,
dann weiß man alles über die Vertelung, was wichtig ist.

Die Verteilungsfunktion ist - wie der Name schon sagt - eine Funktion. Ihr
Definitionsbereich ist die Menge der reellen Zahlen $\mathbb{R}$. Man darf also
jede beliebige Zahl in die Funktion einsetzen. Der Wertebereich der Verteilungsfunktion
ist das Intervall $[0,1]$, da es sich um eine Wahrscheinlichkeit handelt.

Verteilungsfunktionen sind (wegen ihrer Konstruktion) immer monoton wachsend. Sie
verlaufen niemals fallend, es kann jedoch sein, dass sie in einigen Bereichen 
flach verlaufen und nicht steigen. Verteilungsfunktionen können stetig sein,
sie können aber auch Sprünge aufweisen.

Wenn man die Verteilungsfunktion $F_X(x)$ für immer kleinere Werte von $x$ auswertet,
dann erreicht man (zumindest als Grenzwert) die 0, d.h.
$$
\lim_{x\to -\infty} F_X(x)=0.
$$
Für immer größere Werte von $x$ erreicht man (zumindest als Grenzwert) die 1, d.h.
$$
\lim_{x\to\infty} F_X(x)=1.
$$
Alle Verteilungsfunktionen sind monoton (aber nicht unbedingt streng monoton) 
wachsend. Für praktisch alle Anwendungen reicht es aus, sich auf zwei Klassen
von Verteilungsfunktionen einzuschränken. 

- Die eine Klasse sind Treppenfunktionen
(Stufenfunktionen), d.h. die Verteilungsfunktion hat Sprünge und verläuft 
zwischen den Sprüngen waagerecht. Zufallsvariablen, die eine solche
Verteilungsfunktion haben, nennt man diskrete Zufallsvariablen. 

- Die andere Klasse sind stetige Verteilungsfunktionen (d.h. ohne Sprünge).
Zufallsvariablen mit einer stetigen Verteilungsfunktion nennt man
stetige Zufallsvariablen.

Im folgenden wird genauer definiert, wann Zufallsvariablen diskret oder
stetig sind und was für Eigenschaften diskrete und stetige
Zufallsvariablen haben.

## Diskrete Zufallsvariablen

::: callout-note
Eine Zufallsvariable heißt **diskret** (engl. discrete), wenn es 

- endliche viele Punkte $x_1, x_2,\ldots, x_J$ oder
- abzählbar unendlich viele Punkte $x_1, x_2,\ldots$

gibt mit der Eigenschaft 
$$
P(X=x_j)>0
$$
für alle $j$ und
$$
\sum_j P(X=x_j)=1.
$$
:::

Ohne tiefer in die Mengenlehre einzusteigen, sei hier nur erwähnt, dass eine
Menge abzählbar unendlich ist, wenn man ihre Elemente mit den natürlichen 
Zahlen durchnummerieren kann. Abzählbar unendlich sind zum Beispiel die Menge
der natürlichen Zahlen $\mathbb{N}$, die Menge der ganzen Zahlen  $\mathbb{Z}$ 
und die Menge aller Brüche $\mathbb{B}$, nicht jedoch die Menge der
reellen Zahlen  $\mathbb{R}$ oder ein Intervall reeller Zahlen. Letztere
nennt man überabzählbar unendlich.

Die Menge aller Werte, die eine diskret verteilte Zufallsvariable annehmen kann, 
nennt man den Träger (engl. support) der Verteilung. Für endliche viele
Ausprägungen ist der Träger
$$
T_X=\{x_1,\ldots,x_J\},
$$
und für (abzählbar) unendlich viele Ausprägungen ist er
$$
T_X=\{x_1,x_2,x_3,\ldots\}.
$$
Die Funktion 
$$
f(x)=\left\{\begin{array}{ll}
p_j & \text{ wenn }x=x_j\\
0 &\text{ sonst}
\end{array}\right.
$$
heißt **Wahrscheinlichkeitsfunktion**. 

Die Verteilungsfunktion einer diskreten Zufallsvariable ist eine
Treppenfunktion. Der Träger der Zufallsvariable gibt an, an welchen
Stellen die Treppenstufen liegen. Die erste Stufe ist an der Stelle $x_1$,
die zweite an der Stelle $x_2$ etc. Die Stufenhöhen sind $p_1, p_2,\ldots,$.

An der folgenden Abbildung der Verteilungsfunktion einer Zufallsvariablen
$X$ lässt sich also ablesen, dass $X$ diskret verteilt ist, dass $X$ den 
Wert $x_1=0$ mit einer Wahrscheinlichkeit von 0.3 annimmt, den 
Wert $x_2=3$ mit einer Wahrscheinlichkeit von 0.1, den Wert 
$x_3=4$ mit einer Wahrscheinlichkeit von 0.2 und den Wert $x_4=9$ mit
einer Wahrscheinlichkeit von 0.4.

```{r echo=FALSE}
library(ggplot2)
D <- data.frame(x=c(-1,0,3,4,9,10), 
                xend=c(0,3,4,9,10,10),
                y=c(0,0.3,0.4,0.6,1,1))
ggplot(D, aes(x=x, y=y, xend=xend, yend=y)) +
      geom_vline(aes(xintercept=x), linetype=2, color="grey") +
      geom_segment() +
      annotate("point",c(0,3,4,9),c(0.3,0.4,0.6,1))+
      scale_x_continuous("x",breaks=0:10)+
      scale_y_continuous("F(x)",breaks=c(0,0.2,0.4,0.6,0.8,1))+
      ggtitle("Verteilungsfunktion einer diskreten Zufallsvariable")
```


::: callout-tip
- eins

-zwei
:::



## Stetige Zufallsvariablen

::: callout-note
Eine Zufallsvariable $X$ heißt stetig (engl. continuous), wenn es eine
Funktion $f_X(x)$ gibt, so dass
$$
F_X(x)=\int_{-\infty}^x f_X(t)dt
$$
für alle $x\in\mathbb{R}$. Die Funktion $f_X(x)$ heißt **Dichtefunktion**
oder **Dichte** (engl. density function bzw. density). Wenn aus dem Kontext
hervorgeht, zu welcher Zufallsvariable eine Dichte gehört, lässt man den
Subindex gewöhnlich weg und schreibt einfach $f(x)$.
:::

Die Dichte hat folgende Eigenschaften:

- Die Dichte kann nicht negativ sein, da sonst die Verteilungsfunktion
nicht mehr monoton wachsend wäre. Es gilt also $f(x)\le 0$ für alle $x\in\mathbb{R}$.

- Die Fläche unter der Dichte muss 1 ergeben, da jede Verteiliungsfunktion $F_X(x)$
für $x\to\infty$ gegen 1 konvergiert. Es gilt also
$$
\int_{-\infty}^\infty f(x)dx=1.
$$

- Die Dichte gibt an, wie steil die Verteilungsfunktion verläuft. Für
alle Stellen, an denen die Verteilungsfunktion differenzierbar ist, gilt daher
$$
f(x)=F'(x).
$$
Es ist jedoch nicht unbedingt nötig, dass die Verteilungsfunktion überall
differenzierbar ist, sie darf nicht differenzierbare Knicke enthalten.

- Der Wert der Dichte an einer Stelle $x$ ist *keine* Wahrscheinlichkeit.
Hingegen ist die Fläche unter der Dichte eine Wahrscheinlichkeit. So gilt
beispielsweise
$$
P(a<X\le b)=\int_a^b f(x)dx.
$$

- Die Wahrscheinlichkeit, dass eine stetige Zufallsvariable exakt den Wert
$x$ annimmt, ist also (für jedes $x\in\mathbb{R}$)
$$
P(X=x)=0.
$$

::: callout-tip
- eins

-zwei
:::

## Quantilfunktion

Die Quantilfunktion ist das Gegenstück zur Verteilungsfunktion. Während die
Verteilungsfunktion auf die Frage antwortet "Wie hoch ist die Wahrscheinlichkeit,
dass die Zufallsvariable den Wert $x$ nicht übersteigt?", beantwortet die
Quantilfunktion die Frage "Welcher Wert wird mit einer Wahrscheinlichkeit von 
$p$ nicht überschritten?". Da es einige Fälle gibt, in denen diese Frage
nicht eindeutig beantwortet werden kann, ist die formale Definition der
Quantilfunktion etwas komplizierter:

::: callout-note
Die Funktion
$$
F_X^{-1}(p)=\min\{x:F_X(x)\ge p\}
$$
heißt **Quantilfunktion** von $X$. Der Wert $x_p=F_X^{-1}(p)$ heißt **p-Quantil** von $X$
:::

Den Subindex kann man weglassen, wenn sich
die Zufallsvariable aus dem Kontext ergibt. Oft findet man auch die 
alternative Notation $Q(p)$ für die Quantilfunktion.

Es gibt eine Reihe von speziellen Quantilen mit eigener Bezeichnung:

- Median $x_{0.5}$
- Quartile: $x_{0.25}, x_{0.5}, x_{0.75}$
- Quintile: $x_{0.2}, x_{0.4}, x_{0.6}, x_{0.8}$
- Dezile: $x_{0.1}, x_{0.2}, \ldots, x_{0.9}$
- Perzentile: $x_{0.01}, x_{0.02}, \ldots,x_{0.99}$


## Erwartungswert

Der Erwartungswert einer Verteilung gibt Auskunft darüber, wo der
"Schwerpunkt" der Verteilung liegt. 

::: callout-note
Der **Erwartungswert** (engl. expectation) einer Zufallsvariable ist
$$
E(X)=\left\{
\begin{array}{ll}
\sum\limits_{j\in T_X} x_j f(x_j) & \text{ für X diskret}\\
\int\limits_{-\infty}^\infty x f(x)dx & \text{ für X stetig}
\end{array}
\right.
$$
:::

## Varianz

Die Varianz einer Zufallsvariable gibt an, wie stark die Verteilung 
streut bzw. wie sehr man mit großen Abweichungen vom Erwartungswert
rechnen sollte.

::: callout-note
Der **Varianz** (engl. variance) einer Zufallsvariable ist
$$
Var(X)=E\left[(X-E(X))^2\right].
$$
Die (positive) Wurzel aus der Varianz nennt man Standardabweichung
(engl. standard deviation).
:::

Für diskrete und stetige Zufallsvariablen lässt sich die Varianz
folgendermaßen schreiben:
$$
Var(X)==\left\{
\begin{array}{ll}
\sum\limits_{j\in T_X} (x_j-E(X))^2 f(x_j) & \text{ für X diskret}\\
\int\limits_{-\infty}^\infty (x-E(X))^2 f(x)dx & \text{ für X stetig}
\end{array}
\right.
$$

Für die Berechnung der Varianz ist diese Formel oft hilfreich:
$$
Var(X)=E(X^2)-(E(X))^2.
$$

::: callout-tip
- eins

- zwei
:::



## Lineare Transformationen

Eine lineare Transformation einer Zufallsvariable ergibt wieder eine
Zufallsvariable. Für zwei reelle Zahlen $a$ und $b$ ist
$$
Y=aX+b
$$
eine lineare Transformation von $X$. Welche Eigenschaften hat die
transformierte Zufallsvariable $Y$? Wir sehen uns an, wie sich die
Transformation auf die Verteilungsfunktion, den Erwartungswert und die
Varianz auswirkt.

Die Verteilungsfunktion von $Y$ ist für $a>0$
$$
\begin{align*}
F_Y(y) &= P(Y\le y)\\
&= P(aX+b \le y)\\
&= P(aX \le y-b)\\
&= P\left(X \le \frac{y-b}{a}\right)\\
&= F_X\left(\frac{y-b}{a}\right).
\end{align*}
$$
Für $a<0$ dreht sich die Ungleichung bei der Division durch $a$ um, also gilt dann
$$
\begin{align*}
F_Y(y) &= P(Y\le y)\\
&= P(aX+b \le y)\\
&= P(aX \le y-b)\\
&= P\left(X \ge \frac{y-b}{a}\right)\\
&= 1-P\left(X <\frac{y-b}{a}\right).
\end{align*}
$$
Wie die Beziehung des letzten Terms zur Verteilungsfunktion von $X$ aussieht,
lässt sich nicht einfach allgemein beantworten. Wenn $X$ stetig verteilt ist,
macht es keinen Unterschied, ob in der Ungleichung ein "$<$" oder ein "$\le$"
steht, dann ist also
$$
F_Y(y)=1-F_X\left(\frac{y-b}{a}\right).
$$
Wie wirkt sich eine lineare Transformation $Y=aX+b$ auf den Erwartungswert aus?
Wir untersuchen diskrete und stetige Zufallsvariablen getrennt voneinander.
Zuerst betrachten wir eine diskrete Zufallsvariable $X$ und $a,b\in\mathbb{R}$.
Der Erwartungswert von $Y$ ist
$$
\begin{align*}
E(Y) &= E(aX+b)\\
&= \sum_{j\in T_X}(ax_j+b)f(x_j)\\
&= \sum_{j\in T_X}ax_j f(x_j) + \sum_{j\in T_X}b f(x_j)\\
&= a\sum_{j\in T_X}x_j f(x_j) + b\sum_{j\in T_X}f(x_j)\\
&= aE(X)+b,
\end{align*}
$$
denn $\sum_{j\in T_X}f(x_j)=1$. Wenn $X$ eine stetige Zufallsvariable ist,
dann gilt für den Erwartungswert der linearen Transformation
$$
\begin{align*}
E(Y) &= E(aX+b)\\
&= \int_{-\infty}^\infty (ax+b)f(x)dx\\
&= \int_{-\infty}^\infty ax f(x)dx + \int_{-\infty}^\infty b f(x)dx\\
&= a\int_{-\infty}^\infty x f(x)dx + b\int_{-\infty}^\infty f(x)dx\\
&= aE(X)+b,
\end{align*}
$$
weil $\int_{-\infty}^\infty f(x)dx=1$.

Es gilt also sowohl für diskrete als auch für stetige Zufallsvariablen, 
dass der Erwartungswert der linearen Transformation der Zufallsvariable
der linearen Transformation des Erwartungswerts entspricht. Kurz gesagt,
kann man den Erwartungswert in eine lineare Funktion "hineinziehen"
oder ihn aus ihr "herausziehen". Man sagt auch, dass der Erwartungswert
ein "linearer Operator" ist.

*Achtung*: Leider kann man der Erwartungswert im allgemeinen nicht aus anderen
(nichtlinearen) Funktionen herausziehen oder ihn dort hineinziehen.
So ist beispielsweise im allgemeinen
$$
E(X^2) \neq E(X)^2.
$$
Die Ergebnisse zum Erwartungswert können wir nun benutzen, um die
Varianz einer linear transformierten Zufallsvariable zu untersuchen.
Es gilt
$$
\begin{align*}
Var(Y) &= E((Y-E(Y))^2)\\
&= E((aX+b-E(aX+b))^2)\\
&= E((aX+b-(aE(X)+b))^2)\\
&= E((aX+b-aE(X)-b)^2)\\
&= E((aX-aE(X))^2)\\
&= E(a^2(X-E(X))^2)\\
&= a^2 E((X-E(X))^2)\\
&= a^2 Var(X).
\end{align*}
$$
Diese Herleitung gilt sowohl für diskrete als auch für stetige Zufallsvariablen.
Offensichtlich wirkt sich eine additive Verschiebung um $b$ überhaupt nicht
auf die Varianz aus. Eine Multiplikation mit $a$ verändert die Varianz jedoch,
und zwar um den Faktor $a^2$. Wenn $a>1$ ist, wird die Varianz also größer,
wenn $0<a<1$ ist, wird sie kleiner. Beachten Sie, dass es für die Varianz
keine Rolle spielt, ob $a$ positiv oder negativ ist. Insbesondere bleibt die
Varianz unverändert, wenn $X$ mit $(-1)$ multipliziert wird.

## Standardisierung

Eine lineare Transformation, die dazu führt, dass der Erwartungswert der
transformierten Zufallsvariable 0 und die Varianz 1 ist, nennt man 
**Standardisierung**. Die transformierte Zufallsvariable heißt 
standardisiert. Welche lineare Transformation muss für eine
Standardisierung durchgeführt werden? Wie erreicht man, dass der 
Erwartungswert nach der Transformation 0 ist und die Varianz 1?

Wir gehen in zwei Schritten vor. Im ersten Schritt subtrahieren wir von der
Zufallsvariablen $X$ ihren Erwartungswert $E(X)$ (also eine reelle Zahl),
$$
X-E(X).
$$
Die Zufallsvariable $X-E(X)$ hat den Erwartungswert
$$
E(X-E(X))=E(X)-E(X)=0.
$$
Die Varianz von $X-E(X)$ ist gleich der Varianz von $X$, denn die Varianz
verändert sich nicht, wenn eine reelle Zahl addiert oder subtrahiert wird. 
Der Erwartungswert ist eine reelle Zahl. Man nennt die Zufallsvariable
$X-E(X)$ auch **zentriert**.

Im zweiten Schritt dividieren wir $X-E(X)$ durch die Standardabweichung von
$X$,
$$
\frac{X-E(X)}{\sqrt{Var(X)}}.
$$
Dadurch verändert sich der Erwartungswert nicht, er bleibt weiterhin 0. Wie
groß ist die Varianz? Um das zu beantworten, nutzen wir die Ergebisse zu
Varianzen von linearen Transformationen, insb. das Ergebnis, dass eine multiplikative
Konstante aus der Varianz herausgezogen werden kann, dann aber ins Quadrat
gesetzt werden muss. Also ergibt sich
$$
Var\left(
\frac{X-E(X)}{\sqrt{Var(X)}}
\right)=
\frac{1}{Var(X)}Var(X-E(X))=1.
$$
Fassen wir zusammen: Wenn $X$ eine Zufallsvariable mit Erwartungswert $E(X)$
und Varianz $Var(X)$ ist, dann hat die linear transformierte Zufallsvariable
$$
Y=\frac{X-E(X)}{\sqrt{Var(X)}}
$$
den Erwartungswert $E(Y)=0$ und die Varianz $Var(Y)=1$. In der Schreibweise
des vorhergehenden Abschnitts erreicht man eine Standardisierung von $X$ durch
die lineare Transformation $Y=aX+b$ mit $a=1/\sqrt{Var(X)}$ und
$b=E(X)/\sqrt{Var(X)}$.

